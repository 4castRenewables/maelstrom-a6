{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "901e3e02",
   "metadata": {},
   "source": [
    "# Tutorial 2: Numerical weather data\n",
    "\n",
    "**Content creators**: Fabian Emmerich\n",
    "\n",
    "**Content reviewers / testers**: Jannik Jauch\n",
    "\n",
    "In this tutorial, you will get an insight into the data of a numerical weather model. You will learn how these are strucured and what variables they contain. To do so, we will utilize the [`xarray` Python package](https://xarray.pydata.org), which is designed for labeled, multi-dimensional data.\n",
    "\n",
    "## Exercise 1: Create a JupyterLab and select the required Jupyter kernel\n",
    "\n",
    "To complete the following tutorials, you will use a Jupyter kernel which has all required packages installed. A Jupyter kernel provides a software environment to run your notebooks in. For Python, a kernel may provide a set of pre-installed packages. However, it is also possible to use kernels with other software or even for other programming languages that allow interactive computing.\n",
    "\n",
    "1. Launch a JupyerLab on a login node via JupyterJSC and launch a terminal. Continue this notebook from there.\n",
    "1. To create a custom kernel, you have to create a config file (`kernel.json`) in a directory in the `~/.local/share/jupyter/kernels` path, which Jupyter scans for custom configurations.\n",
    "   1. Create a folder namend `maelstrom-bootcamp` in the required path\n",
    "      ```bash\n",
    "      mkdir -p ~/.local/share/jupyter/kernels/maelstrom-bootcamp\n",
    "      ```\n",
    "   1. Create a `kernel.json` file in the previously created path by executing the below cell. The `%%file <file path>` magic command at the top of the cell will write the content of the respective cell to the given path (file).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ce9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ~/.local/share/jupyter/kernels/maelstrom-bootcamp/kernel.json\n",
    "{\n",
    " \"argv\": [\n",
    "   \"apptainer\",\n",
    "   \"exec\",\n",
    "   \"--cleanenv\",\n",
    "   \"-B /usr/:/host/usr/, /etc/slurm:/etc/slurm, /usr/lib64:/host/usr/lib64, /opt/parastation:/opt/parastation, /usr/lib64/slurm:/usr/lib64/slurm, /usr/share/lua:/usr/share/lua, /usr/lib64/lua:/usr/lib64/lua, /opt/jsc:/opt/jsc, /var/run/munge:/var/run/munge\",\n",
    "   \"/p/project/training2223/a6/jupyter-kernel.sif\",\n",
    "   \"python\",\n",
    "   \"-m\",\n",
    "   \"ipykernel\",\n",
    "   \"-f\",\n",
    "   \"{connection_file}\"\n",
    " ],\n",
    " \"language\": \"python\",\n",
    " \"display_name\": \"maelstrom-bootcamp\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50215158",
   "metadata": {},
   "source": [
    "The `display_name` field in the above JSON structure will be the name under which the kernel will appear in the JupyterLab. \n",
    "\n",
    "The `argv` array contains the command that will be executed when the kernel is loaded by Jupyter. Here, we run a command inside an Apptainer image (`apptainer exec [...] jupyter-kernel.sif`) that launches a file with an ipykernel (`python -m ipykernel`). The other arguments passed to the command will allow us to use the software of the system (e.g. Slurm) from within the kernel.\n",
    "\n",
    "Apptainer, formerly known as Singularity, is a container runtime that was designed for usage on high-performance systems. Containers in general enable to create software environments that can be run on any host, but are separated from the host's operating system. In general, such containers allow installing any software and run it on any system without requiring prerequisites - except Apptainer, of course. As a consequence, they provide the maximum amount of reproducibility. The Apptainer image we use here basically provides a Python environment with a set of packages that you will need to complete the rest of the tutorials.\n",
    "\n",
    "You can directly check whether setting up the kernel via `jupyter kernelspec list`, which should return a list of all available kernels and their paths. This list should include a kernel with the path from above (`/p/home/jusers/<user>/juwels/.local/share/jupyter/kernels/maelstrom-bootcamp`).\n",
    "\n",
    "You can execute this command directly from this notebook (see below cell) by using the magic command `!`, which executes the given command in the underlying shell (terminal) of the system (e.g. bash)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf952dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1e90d",
   "metadata": {},
   "source": [
    "1. Now, in the top menu bar, navigate to `Kernel > Change Kernel...`\n",
    "   <img src=\"./images/jupyterlab-kernel.png\" width=\"60%\" height=\"60%\">\n",
    "1. From the popup's dropdown, select the kernel `maelstrom-bootcamp`.\n",
    "1. Once the kernel is loaded, you will see it on the top right of the notebook.\n",
    "\n",
    "   <img src=\"./images/jupyterlab-kernel-status.png\" width=\"60%\" height=\"60%\">\n",
    "   \n",
    "   Hovering over the circle to the right of the name will show you the status of the kernel.\n",
    "   Clicking on the field that contains the name of the kernel also allows you to switch the kernel as in step 1.\n",
    "   \n",
    "\n",
    "## Exercise 2: First insight into data of a numerical weather model\n",
    "\n",
    "In this tutorial, we will use data from the ECMWF IFS HRES model. ECMWF, which is an acronym for the European Center for Medium-Range Weather Forecasts, is a multi-national research institue for numerical weather predictions and climate. ECMWF created a set of numerical weather models for different purposes. For a general overview see [here](https://www.ecmwf.int/en/forecasts/documentation-and-support). The models differ from one another in different aspects, e.g.:\n",
    "\n",
    "- Forecast horizon\n",
    "- Spatial resolution\n",
    "- Number of vertical levels (altitudes)\n",
    "- Model complexity\n",
    "- Phyiscal output quantities\n",
    "\n",
    "The [ECMWF IFS HRES model](https://www.ecmwf.int/en/forecasts/datasets/set-i) is - as its name implies - a high-resolution model with a spatial resolution of $\\sim 0.1Â°$, which corresponds to $\\sim 9\\,\\mathrm{km}$. It has different output formats:\n",
    "\n",
    "- Single level (surface level)\n",
    "- Pressure levels\n",
    "- Model levels\n",
    "- Potential vorticity levels\n",
    "\n",
    "We will now make use of `xarray` to load some of the data from the model levels and take a look at the data structure. \n",
    "\n",
    "There are a bunch of data formats used in meteorology. Two of the most common ones are GRIB and NetCDF. Here, we use data stored in the NetCDF format, which is supported by xarray.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Take a look at the folder located at `/p/project/training2223/a6/data/ml`. Which files are located there and what pattern can you recognize from their names?\n",
    "1. Load one of the data files with xarray, which provides a method [`xarray.open_dataset`](https://docs.xarray.dev/en/stable/generated/xarray.open_dataset.html) that allows reading files of different formats. \n",
    "1. The above method returns a [`xarray.Dataset`](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.html), which is a data object that allows accessing the underlying data in a quite handy way. Take some time to investigate the dataset. Take a look at the documentation of xarray to find the required methods for the following tasks:\n",
    "   1. What coordinates does the dataset use and in what order? What are their value ranges and resolution (step size)?\n",
    "   1. Does the dataset contain any metadata?\n",
    "   1. Which variables are contained in the given dataset?\n",
    "   1. Take a deeper look at one ore more of these variables. How can you access them? Which physical quantity do they represent and what is their unit? What is their shape?\n",
    "   1. Make a plot of one level and time step of one of these variables. \n",
    "   \n",
    "      *Hint:* xarray has builtin methods that make it easy to plot variables!\n",
    "1. Load another data file. Take a look at the time stamps of this and the previous dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a639922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 1\n",
    "%load ./solutions/tutorial-2/task-2-1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 2\n",
    "%load ./solutions/tutorial-2/task-2-2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869927b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 3\n",
    "%load ./solutions/tutorial-2/task-2-3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd92d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 4\n",
    "%load ./solutions/tutorial-2/task-2-4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f85337",
   "metadata": {},
   "source": [
    "The IFS HRES model runs four model runs per day: at 00:00, 06:00, 12:00, 18:00 for 90 hours each with an hourly resolution. It furthermore provides $L = [1, 137]$ model levels, where $L = 137$ is the lowest (from surface), and $L = 1$ the highest level. The data used here only contain the lowest ten levels $L = [128, 137]$. Although the model provides a large variety of physical output quantities, we here though only make use of four:\n",
    "\n",
    "1. Temperature $t$ $[\\mathrm{K}]$\n",
    "1. Specific Humidity $q$ $[\\mathrm{kg}/\\mathrm{kg}]$\n",
    "1. Azimuthal wind speed $u$ $[\\mathrm{m}/\\mathrm{s}]$\n",
    "1. Vertical wind speed $v$ $[\\mathrm{m}/\\mathrm{s}]$\n",
    "\n",
    "The coordinates used are \n",
    "\n",
    "1. Time\n",
    "1. Altitude\n",
    "1. Latitude\n",
    "1. Longitude\n",
    "\n",
    "The order of these follows the [CF 1.6 conventions for NetCDF data](https://cfconventions.org/cf-conventions/v1.6.0/cf-conventions.html#dimensions), which is also given in the datasets metadata.\n",
    "\n",
    "As you can see from the plot, the data cover the whole of Europe. As stated above, the data is given at a resolution of $\\sim 10\\,\\mathrm{km}$. Plotting the temperature field nicely enables you to identify and distinguish the continential oceanic areas.\n",
    "\n",
    "## Exercise 3: Merging Datasets\n",
    "\n",
    "Looking at the intersection of the time stamps, you see that there are overlapping time steps. As stated above, there are four model runs per day with 90 hours forecast horizon at an hourly temporal resolution. (Here, we only have a horizon of 48 hours.) As a result, subsequent model runs have overlapping time steps, i.e. they have duplicate values.\n",
    "\n",
    "As their name states, numerical weather models are based on numerical modeling: they use numerical schemes to solve the underlying phyiscal equations that govern the physical laws of the weather system. These schemes result in numerical errors that propagate and bloat up with time. Hence, we here will only use data from the most recent model runs for each time step.\n",
    "\n",
    "### Tasks\n",
    "1. Given the data for `20200101_00`, `20200101_12`, `20200102_00` and `20200102_12`, think of a method that gives us the most recent data for each time step.\n",
    "1. Construct a single dataset that contains all the given data files without any duplicate time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c84fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 2\n",
    "%load ./solutions/tutorial-2/task-3-2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722bf41",
   "metadata": {},
   "source": [
    "## Exercise 4: Wind power production data\n",
    "\n",
    "As a last step, we will take a look at the data of a wind turbine. For this purpose, we are provided with real production data from a wind turbine located in Germany. The geographical location and elevation of the wind turbine are given in the data.\n",
    "\n",
    "### Tasks\n",
    "1. Load the data of the wind turbine located at `/p/project/training2223/a6/data/wind_turbine.nc` and get familiar with the data:\n",
    "   1. Where is the wind turbine located? \n",
    "   \n",
    "      *Hint:* You can use `xr.DataArray.values` to directly get the the underlying data of a `xr.DataArray` (or `xr.Dataset`).\n",
    "   1. What quantities are provided for the wind turbine and what are their units? \n",
    "   1. What is the temporal resolution of the data?\n",
    "   1. Plot each of the quantities.\n",
    "1. Plot the given quantities (on the y-axis) in a figure, where the x-axis is the time axis.\n",
    "   To get a better view, select a small time window of the entire time series.\n",
    "   Can you observe a correlation between the quantities? \n",
    "   \n",
    "   *Hint:* Use the `utils.create_twin_y_axis_plot()` method from the [`utils`](./utils.py) module located in the folder of this notebook.\n",
    "1. A good measure for linear correlations between two quantities is the [Pearson correlation coefficient](https://statistics.laerd.com/statistical-guides/pearson-correlation-coefficient-statistical-guide.php). \n",
    "   1. Plot wind speed vs. power production (on x- and y-axis, respectively) as a scatter plot. Can you see what kind of correlation the two quantities indicate?\n",
    "   1. Calculate the correlation between the given quantities. Does this match with your eyeball analysis from the previos task?\n",
    "   \n",
    "      *Hint:* The calculation of the Pearson correlation is already implemented in a lot of Python packages. Don't reinvent the wheel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 1\n",
    "%load ./solutions/tutorial-2/task-4-1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 2\n",
    "%load ./solutions/tutorial-2/task-4-2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ed9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 3\n",
    "%load ./solutions/tutorial-2/task-4-3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e9253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
