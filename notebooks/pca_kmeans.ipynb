{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3224fe85-9303-405a-842f-d37f609ced79",
   "metadata": {},
   "source": [
    "# PCA + k-Means on ERA5 Data\n",
    "\n",
    "## Results\n",
    "\n",
    "- Data loading takes ~5min\n",
    "- Data preprocessing takes ~4min\n",
    "- PCA with 500 PCs takes ~8min\n",
    "- PCA (reduced PCs), Transforming and clustering (2 x k-Means) takes ~2min\n",
    "- kPCA with 500 PCs takes ~2min\n",
    "- kPCA (reduced PCs), Transforming and clustering (2 x k-Means) takes ~3min\n",
    "- PCA:\n",
    "  - N_pcs=24 cover 0.7 of the variance\n",
    "  - N_pcs=80 cover 0.8 of the variance\n",
    "  - N_pcs=171 cover 0.85 of the variance\n",
    "  - N_pcs=421 cover 0.9 of the variance\n",
    "- kPCA:\n",
    "  - N_pcs=1 cover 0.4 of the variance\n",
    "  - N_pcs=2 cover 0.5 of the variance\n",
    "  - N_pcs=3 cover 0.6000000000000001 of the variance\n",
    "  - N_pcs=6 cover 0.7000000000000001 of the variance\n",
    "  - N_pcs=15 cover 0.8 of the variance\n",
    "  - N_pcs=54 cover 0.9 of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c399384-faab-40e3-8b72-ce854b99d5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datetime\n",
    "import pathlib\n",
    "import joblib\n",
    "\n",
    "import sklearn.cluster\n",
    "import sklearn.decomposition\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import a6\n",
    "import a6.plotting._colors as _colors\n",
    "\n",
    "path = pathlib.Path(\n",
    "    \"/p/project/deepacf/emmerich1/data/ecmwf_era5/era5_pl_1964_2023_12.nc\"\n",
    ")\n",
    "plots = pathlib.Path(\"/p/project/deepacf/emmerich1/plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8901c-6af3-44d2-a689-7bfe58b49de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds = xr.open_dataset(path)\n",
    "\n",
    "coordinates = a6.datasets.coordinates.Coordinates()\n",
    "variables = a6.datasets.variables.Model()\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82c29b-257d-46ae-bd34-342981d7c0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "masked = a6.datasets.methods.mask.set_nans_to_mean(ds, coordinates=coordinates)\n",
    "data = (\n",
    "    (\n",
    "        a6.features.methods.weighting.weight_by_latitudes(\n",
    "            latitudes=coordinates.latitude,\n",
    "            use_sqrt=True,\n",
    "        )\n",
    "        >> a6.features.methods.reshape.xarray.reshape_spatio_temporal_data(\n",
    "            # Set to None to avoid memory excess in function\n",
    "            time_coordinate=None,\n",
    "        )\n",
    "        >> a6.features.methods.standardization.normalize_features()\n",
    "    )\n",
    "    .apply_to(masked)\n",
    "    .compute()\n",
    ")\n",
    "del ds\n",
    "del masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40d205-2611-414e-8269-53b6ad319402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# data.to_netcdf(\"/p/project/deepacf/emmerich1/data/ecmwf_era5/era5_pl_1964_2023_12_preprocssed_for_pca.nc\")\n",
    "# del data\n",
    "\n",
    "data = (\n",
    "    xr.open_dataset(\n",
    "        \"/p/project/deepacf/emmerich1/data/ecmwf_era5/era5_pl_1964_2023_12_preprocssed_for_pca.nc\"\n",
    "    )\n",
    "    .to_dataarray()\n",
    "    .values[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b673b37-0dfb-48d8-a689-deeeb61cd732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# pca = sklearn.decomposition.PCA(n_components=500).fit(data)\n",
    "pca = joblib.load(\"/p/project/deepacf/emmerich1/data/pca_500_pcs.joblib\")\n",
    "cum_evr = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ba943-ab8b-45c0-ba9c-e6db20dba516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plt.plot(list(range(pca.n_components_)), cum_evr)\n",
    "for var in np.arange(0, 1.0, 0.1):\n",
    "    n_pcs = np.where(cum_evr > var)[0][0]\n",
    "    print(f\"N_pcs={n_pcs} cover {var} of the variance\")\n",
    "n_pcs = np.where(cum_evr > 0.80)[0][0]\n",
    "transformed = sklearn.decomposition.PCA(n_components=n_pcs).fit_transform(data)\n",
    "kmeans_pca_40 = sklearn.cluster.KMeans(n_clusters=40).fit(transformed)\n",
    "kmeans_pca_30 = sklearn.cluster.KMeans(n_clusters=30).fit(transformed)\n",
    "\n",
    "kmeans_pca_40_labels = kmeans_pca_40.labels_\n",
    "kmeans_pca_30_labels = kmeans_pca_30.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4222fc-1858-4335-acd6-9700590994b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(pca, \"/p/project/deepacf/emmerich1/data/pca_500_pcs.joblib\")\n",
    "joblib.dump(\n",
    "    kmeans_pca_40, \"/p/project/deepacf/emmerich1/data/kmeans_pca_40.joblib\"\n",
    ")\n",
    "joblib.dump(\n",
    "    kmeans_pca_30, \"/p/project/deepacf/emmerich1/data/kmeans_pca_30.joblib\"\n",
    ")\n",
    "\n",
    "del pca\n",
    "del transformed\n",
    "del kmeans_pca_40\n",
    "del kmeans_pca_30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c04eea-f999-440d-8ab6-dbdc94b8e414",
   "metadata": {},
   "source": [
    "Kernel PCA: Gaussian radial basis function with $\\sigma = 200$ (see http://dx.doi.org/10.1016/j.procs.2011.08.043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342af78d-e030-4dd5-a739-87da35235122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kpca = sklearn.decomposition.KernelPCA(\n",
    "    n_components=500,\n",
    "    copy_X=False,\n",
    ").fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89ee4d-822e-45ca-8074-c4fef0663c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cum_evr = np.cumsum(kpca.eigenvalues_ / np.sum(kpca.eigenvalues_))\n",
    "plt.plot(list(range(len(kpca.eigenvalues_))), cum_evr)\n",
    "for var in np.arange(0, 1.0, 0.1):\n",
    "    n_pcs = np.where(cum_evr > var)[0][0]\n",
    "    print(f\"N_pcs={n_pcs} cover {var} of the variance\")\n",
    "n_pcs = np.where(cum_evr > 0.80)[0][0]\n",
    "transformed = sklearn.decomposition.KernelPCA(\n",
    "    n_components=n_pcs, copy_X=False\n",
    ").fit_transform(data)\n",
    "kmeans_kpca_40 = sklearn.cluster.KMeans(n_clusters=40).fit(transformed)\n",
    "kmeans_kpca_30 = sklearn.cluster.KMeans(n_clusters=30).fit(transformed)\n",
    "\n",
    "kmeans_kpca_40_labels = kmeans_pca_40.labels_\n",
    "kmeans_kpca_30_labels = kmeans_pca_30.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5662d12-0c9d-4850-a77c-edde44cad229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "joblib.dump(kpca, \"/p/project/deepacf/emmerich1/data/kpca_500_pcs.joblib\")\n",
    "joblib.dump(\n",
    "    kmeans_kpca_40, \"/p/project/deepacf/emmerich1/data/kmeans_kpca_40.joblib\"\n",
    ")\n",
    "joblib.dump(\n",
    "    kmeans_kpca_30, \"/p/project/deepacf/emmerich1/data/kmeans_kpca_30.joblib\"\n",
    ")\n",
    "\n",
    "del kpca\n",
    "del transformed\n",
    "del kmeans_kpca_40\n",
    "del kmeans_kpca_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa70ea-c233-40d4-80ef-4df17fb8ffb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds = xr.open_dataset(path)\n",
    "\n",
    "# Add +1 to be conform to the GWL labels\n",
    "kmeans_pca_40 = joblib.load(\n",
    "    \"/p/project/deepacf/emmerich1/data/kmeans_pca_40.joblib\"\n",
    ")\n",
    "kmeans_pca_30 = joblib.load(\n",
    "    \"/p/project/deepacf/emmerich1/data/kmeans_pca_30.joblib\"\n",
    ")\n",
    "kmeans_pca_40_labels = kmeans_pca_40.labels_ + 1\n",
    "kmeans_pca_30_labels = kmeans_pca_30.labels_ + 1\n",
    "\n",
    "kmeans_kpca_40 = joblib.load(\n",
    "    \"/p/project/deepacf/emmerich1/data/kmeans_kpca_40.joblib\"\n",
    ")\n",
    "kmeans_kpca_30 = joblib.load(\n",
    "    \"/p/project/deepacf/emmerich1/data/kmeans_kpca_30.joblib\"\n",
    ")\n",
    "kmeans_kpca_40_labels = kmeans_kpca_40.labels_ + 1\n",
    "kmeans_kpca_30_labels = kmeans_kpca_30.labels_ + 1\n",
    "\n",
    "# Need to convert dates to YYYY-MM-DD to be conform with GWL dataset time stamps.\n",
    "times = a6.utils.times.get_time_steps_as_dates(ds, coordinates=coordinates)\n",
    "\n",
    "results = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"PCA\": (\n",
    "            [\"time\", \"k\"],\n",
    "            list(zip(kmeans_pca_30_labels, kmeans_pca_40_labels)),\n",
    "        ),\n",
    "        \"kPCA\": (\n",
    "            [\"time\", \"k\"],\n",
    "            list(zip(kmeans_kpca_30_labels, kmeans_kpca_40_labels)),\n",
    "        ),\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": times,\n",
    "        \"k\": [30, 40],\n",
    "    },\n",
    "    attrs={\n",
    "        \"description\": \"Resulting LSWR labels from K-Means clustering on PCA and kernel PCA of the ERA5 data (1964-2023)\",\n",
    "    },\n",
    ")\n",
    "results.to_netcdf(\n",
    "    \"/p/project/deepacf/emmerich1/data/pca_kpca_kmeans_lswrs_30_40.nc\"\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e0ee0f-cfa0-4618-bf48-1d2cf490f0cf",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf842b5-203c-4ea8-a9bd-d35a0e22a120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = xr.open_dataset(\n",
    "    \"/p/project/deepacf/emmerich1/data/pca_kpca_kmeans_lswrs_30_40.nc\"\n",
    ")\n",
    "results_40 = results.sel(k=40)\n",
    "gwl = xr.open_dataset(\n",
    "    \"/p/home/jusers/emmerich1/juwels/code/a6/src/tests/data/gwl.nc\"\n",
    ")\n",
    "\n",
    "dcv2 = torch.load(\n",
    "    \"/p/scratch/deepacf/emmerich1/dcv2/multi-level-all-fields-1964-2023/results/tensors/epoch-799-assignments.pt\",\n",
    "    map_location=torch.device(\"cpu\"),\n",
    ")\n",
    "dcv2 = xr.DataArray(\n",
    "    # Need to add +1 to be conform with GWL labels\n",
    "    dcv2.numpy()[0] + 1,\n",
    "    name=\"DCv2\",\n",
    "    coords={\"time\": results[\"time\"]},\n",
    "    dims=[\"time\"],\n",
    ")\n",
    "lswrs = [gwl[\"GWL\"], results_40[\"PCA\"], results_40[\"kPCA\"], dcv2]\n",
    "\n",
    "\n",
    "dcv2.to_netcdf(\"/p/project/deepacf/emmerich1/data/dcv2-lswrs.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae4e6c-a69e-4d80-a7c3-2a2a4af38f41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = joblib.load(\"/p/project/deepacf/emmerich1/data/pca_500_pcs.joblib\")\n",
    "kpca = joblib.load(\"/p/project/deepacf/emmerich1/data/kpca_500_pcs.joblib\")\n",
    "\n",
    "pca_cum_evr = np.cumsum(pca.explained_variance_ratio_)\n",
    "kpca_evr = kpca.eigenvalues_ / np.sum(kpca.eigenvalues_)\n",
    "kpca_cum_evr = np.cumsum(kpca_evr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3dd56-fc36-48a4-a6a7-4cf1c1fcb8b5",
   "metadata": {},
   "source": [
    "## Explained Variance Ratio Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9bf5e-5321-4343-89b0-9fede28110ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax1.set_xlabel(\"PCs\")\n",
    "\n",
    "x = list(range(1, pca.n_components + 1))\n",
    "\n",
    "# Plot cumulative variance on first axis\n",
    "ax1_color = \"green\"\n",
    "ax1.set_ylabel(\"cumulative explained variance\", color=ax1_color)\n",
    "ax1.plot(x, pca_cum_evr, color=ax1_color, linestyle=\"-\", label=\"PCA\")\n",
    "ax1.plot(x, kpca_cum_evr, color=ax1_color, linestyle=\"-.\", label=\"kPCA\")\n",
    "\n",
    "# Create right axis.\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the explained variance ratios.\n",
    "ax2_color = \"blue\"\n",
    "ax2.set_ylabel(\"explained variance ratio\", color=ax2_color)\n",
    "ax2.plot(\n",
    "    x,\n",
    "    pca.explained_variance_ratio_,\n",
    "    color=ax2_color,\n",
    "    linestyle=\"-\",\n",
    "    label=\"PCA\",\n",
    ")\n",
    "ax2.plot(x, kpca_evr, color=ax2_color, linestyle=\"-.\", label=\"kPCA\")\n",
    "\n",
    "for ax, color in [(ax1, ax1_color), (ax2, ax2_color)]:\n",
    "    # Set log scale.\n",
    "    ax.set(xscale=\"log\", yscale=\"log\")\n",
    "    # Set left xlim such that the first tick disappears.\n",
    "    ax.set_xlim(0.91, None)\n",
    "    # Color the ticks.\n",
    "    ax.tick_params(axis=\"y\", colors=color, which=\"both\")\n",
    "\n",
    "\n",
    "# Plot vertical lince indicating variance excess.\n",
    "variance = 0.8\n",
    "for cum_evr, title in [(pca_cum_evr, \"PCA\"), (kpca_cum_evr, \"kPCA\")]:\n",
    "    n_pcs = np.where(cum_evr > variance)[0][0]\n",
    "    # Dashed line indicating the threshold.\n",
    "    ax2.axvline(\n",
    "        n_pcs,\n",
    "        ymin=0,\n",
    "        ymax=1.1,\n",
    "        linestyle=\"dashed\",\n",
    "        color=\"grey\",\n",
    "    )\n",
    "    ax2.text(\n",
    "        1.04 * n_pcs,\n",
    "        0.001,\n",
    "        f\"$N_{{PCs}} = {n_pcs}$ ({title})\",\n",
    "        rotation=90,\n",
    "        color=\"grey\",\n",
    "    )\n",
    "ax1.set_title(\"Explained Variances for PCA and kPCA\")\n",
    "ax2.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(plots / \"explained-variance-pca-kpca.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9bc2d2-5cba-46cd-b050-4e37d68c40bf",
   "metadata": {},
   "source": [
    "## LSWR Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316179e-16c7-46c8-a259-da5cb3711849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_abundance(\n",
    "    assignments: list[xr.DataArray],\n",
    ") -> None:\n",
    "    n_subplots = len(assignments)\n",
    "    labels = np.arange(\n",
    "        int(assignments[0].min()), int(assignments[0].max()) + 1, 1, dtype=int\n",
    "    )\n",
    "    x_lims = labels.min() - 0.5, labels.max() + 0.5\n",
    "    bins = np.arange(x_lims[0], x_lims[1] + 1.0, 1.0)\n",
    "    colors = _colors.create_colors_for_labels(labels)\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        figsize=(6, 2 * n_subplots),\n",
    "        nrows=n_subplots,\n",
    "        ncols=1,\n",
    "        sharex=True,\n",
    "        sharey=False,\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Abundance of LSWRs\")\n",
    "\n",
    "    for i, element in enumerate(assignments):\n",
    "        _, _, patches = axs[i].hist(element, bins=bins, density=True)\n",
    "\n",
    "        axs[i].set_title(element.name)\n",
    "\n",
    "        if i == n_subplots - 1:\n",
    "            axs[i].set_xlabel(\"LSWR\")\n",
    "\n",
    "        axs[i].set_ylabel(\"Abundance [%]\")\n",
    "        axs[i].set_xlim(*x_lims)\n",
    "        axs[i].set_xticks(labels)\n",
    "        axs[i].set_xticklabels(labels, rotation=90)\n",
    "        axs[i].yaxis.grid(True)\n",
    "\n",
    "        # ax2 = axs[i].twinx()\n",
    "        # _, _, patches = ax2.hist(element, bins=bins, density=True)\n",
    "        # ax2.set_ylabel(\"Relative [%]\")\n",
    "\n",
    "        if len(colors) != len(patches):\n",
    "            raise RuntimeError(\n",
    "                \"Length of colors does not match number of patches in histogram\"\n",
    "            )\n",
    "\n",
    "        for color, patch in zip(colors, patches):\n",
    "            patch.set_facecolor(color)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(plots / \"lswrs-abundance-comparison.pdf\")\n",
    "\n",
    "\n",
    "plot_abundance(lswrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93511d32-db51-497b-ba92-97b0cc336ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_transition_matrix_heatmap(\n",
    "    assignments: list[xr.DataArray],\n",
    ") -> None:\n",
    "    n_subplots = len(assignments)\n",
    "    width_ratios = [1 for _ in enumerate(assignments)] + [0.08]\n",
    "\n",
    "    # Add 1 subplot just for the colorbar\n",
    "    fig, axs = plt.subplots(\n",
    "        figsize=(6 * n_subplots, 6),\n",
    "        nrows=1,\n",
    "        ncols=n_subplots + 1,\n",
    "        gridspec_kw={\"width_ratios\": width_ratios},\n",
    "    )\n",
    "\n",
    "    # Last element of axs is the cbar\n",
    "    for ax1, ax2 in itertools.pairwise(axs[:-1]):\n",
    "        ax1.sharey(ax2)\n",
    "\n",
    "    axs_cbar = axs[-1]\n",
    "    transitions = np.array(\n",
    "        [\n",
    "            a6.plotting.transitions._calculate_markov_transition_matrix(a)\n",
    "            for a in assignments\n",
    "        ]\n",
    "    )\n",
    "    max_prob = transitions.max()\n",
    "    min_prob = transitions.min()\n",
    "\n",
    "    for i, element in enumerate(assignments):\n",
    "        transition = transitions[i]\n",
    "        kwargs = (\n",
    "            {\"cbar\": False}\n",
    "            if i < n_subplots - 1\n",
    "            else {\"cbar_ax\": axs_cbar, \"cbar_kws\": {\"label\": \"probability\"}}\n",
    "        )\n",
    "        sns.heatmap(\n",
    "            transition,\n",
    "            ax=axs[i],\n",
    "            cmap=\"Reds\",\n",
    "            vmin=min_prob,\n",
    "            vmax=max_prob,\n",
    "            **kwargs\n",
    "        )\n",
    "        axs[i].set_title(element.name)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(plots / \"lswrs-transition-probabilities-comparison.pdf\")\n",
    "\n",
    "\n",
    "plot_transition_matrix_heatmap(lswrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8a003b-5c3f-402d-ab97-09c0ff72f345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_modes_durations(\n",
    "    assignments: list[xr.DataArray],\n",
    ") -> tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"Plot the mode mean durations and standard deviation.\"\"\"\n",
    "    n_subplots = len(assignments)\n",
    "    modes = [\n",
    "        a6.modes.methods.determine_lifetimes_of_modes(a) for a in assignments\n",
    "    ]\n",
    "    labels = np.arange(1, modes[0].size + 1, 1, dtype=int)\n",
    "\n",
    "    x_lims = labels.min() - 0.5, labels.max() + 0.5\n",
    "    colors = _colors.create_colors_for_labels(labels)\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        figsize=(6, 2 * n_subplots),\n",
    "        nrows=n_subplots,\n",
    "        ncols=1,\n",
    "        sharex=True,\n",
    "        sharey=False,\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Duration of LSWRs\")\n",
    "\n",
    "    for i, element in enumerate(modes):\n",
    "        (\n",
    "            durations,\n",
    "            stds,\n",
    "        ) = a6.plotting.modes.statistics._calculate_mean_durations_and_standard_deviations(\n",
    "            element\n",
    "        )\n",
    "        axs[i].bar(\n",
    "            labels,\n",
    "            durations,\n",
    "            yerr=stds,\n",
    "            width=1.0,  # removes gaps between the bars\n",
    "            color=colors,\n",
    "            align=\"center\",\n",
    "            alpha=1,\n",
    "            ecolor=\"black\",\n",
    "            capsize=3,\n",
    "        )\n",
    "\n",
    "        axs[i].set_title(assignments[i].name)\n",
    "\n",
    "        if i == n_subplots - 1:\n",
    "            axs[i].set_xlabel(\"LSWR\")\n",
    "\n",
    "        axs[i].set_ylabel(\"Mean duration [days]\")\n",
    "        axs[i].set_xlim(*x_lims)\n",
    "        axs[i].set_xticks(labels)\n",
    "        axs[i].set_xticklabels(labels, rotation=90)\n",
    "        axs[i].yaxis.grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(plots / \"lswrs-durations-comparison.pdf\")\n",
    "\n",
    "\n",
    "plot_modes_durations(lswrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9857305c-36c7-4e71-94a5-e8fd612e9524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def calculate_mean_and_std(data: xr.Dataset, assignments: xr.DataArray):\n",
    "    subset = (\n",
    "        a6.datasets.methods.select.select_levels(levels=500)\n",
    "        >> a6.features.methods.geopotential.calculate_geopotential_height()\n",
    "    ).apply_to(data)\n",
    "\n",
    "    modes = a6.modes.methods.determine_lifetimes_of_modes(assignments)\n",
    "    dates = [list(mode.get_dates()) for mode in modes]\n",
    "    z_h_per_mode = [\n",
    "        subset[\"z_h\"].sel(time=date, method=\"nearest\") for date in dates\n",
    "    ]\n",
    "\n",
    "    means = [z_h.mean(\"time\") for z_h in z_h_per_mode]\n",
    "    means_max = max(mean.max() for mean in means)\n",
    "    means_min = min(mean.min() for mean in means)\n",
    "\n",
    "    stds = [z_h.std(\"time\") for z_h in z_h_per_mode]\n",
    "    stds_max = max(std.max() for std in stds)\n",
    "    stds_min = min(std.min() for std in stds)\n",
    "\n",
    "    return (\n",
    "        assignments.name,\n",
    "        modes,\n",
    "        means,\n",
    "        means_min,\n",
    "        means_max,\n",
    "        stds,\n",
    "        stds_min,\n",
    "        stds_max,\n",
    "    )\n",
    "\n",
    "\n",
    "means_stds = [\n",
    "    calculate_mean_and_std(data=ds, assignments=assignments)\n",
    "    for assignments in lswrs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68208700-4f58-43d2-bb4a-1957b24633bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "\n",
    "def round_to_decade(value: xr.DataArray) -> int:\n",
    "    return int(np.round(value.values, -1))\n",
    "\n",
    "\n",
    "def plot_geopotential_mean_and_std(\n",
    "    name: str,\n",
    "    modes,\n",
    "    means: list[xr.DataArray],\n",
    "    means_min: float,\n",
    "    means_max: float,\n",
    "    stds: list[xr.DataArray],\n",
    "    stds_min: float,\n",
    "    stds_max: float,\n",
    ") -> tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"Plot geopotential height contours, temperature and wind speed.\"\"\"\n",
    "    labels = np.arange(1, modes.size + 1, 1, dtype=int)\n",
    "\n",
    "    n_rows = 8\n",
    "    n_cols = 5\n",
    "\n",
    "    if n_rows * n_cols != labels.max():\n",
    "        raise ValueError(\"Number of plots not equal to number of LSWRs\")\n",
    "\n",
    "    height = n_rows * 2\n",
    "    width = n_cols * 2.5\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        figsize=(width, height),\n",
    "        nrows=n_rows,\n",
    "        # Add 2 columns for colorbars\n",
    "        # ncols=n_cols + 2,\n",
    "        ncols=n_cols,\n",
    "        subplot_kw=a6.plotting.coastlines.create_projection(),\n",
    "        # gridspec_kw={\"width_ratios\": [1 for _ in range(n_cols)] + [0.05, 0.05]},\n",
    "    )\n",
    "    levels = list(\n",
    "        range(\n",
    "            round_to_decade(means_min),\n",
    "            round_to_decade(means_max),\n",
    "            5,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        z_h_mean = means[i]\n",
    "        z_h_std = stds[i]\n",
    "        heatmap = z_h_std.plot(\n",
    "            ax=ax,\n",
    "            cmap=\"RdBu\",\n",
    "            vmin=stds_min,\n",
    "            vmax=stds_max,\n",
    "            add_colorbar=False,\n",
    "        )\n",
    "\n",
    "        contours = z_h_mean.plot.contour(\n",
    "            ax=ax,\n",
    "            levels=levels,\n",
    "            cmap=\"cool\",\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            linewidths=1.0,\n",
    "        )\n",
    "        # contours.clabel(inline=True)\n",
    "        #         handles_unfilled, labels = cs_unfilled.legend_elements()\n",
    "\n",
    "        #         ax.legend(handles_filled + handles_unfilled,\n",
    "        #                   [\"range(2-3)\", \"range(3-4)\", \"range(4-6)\", \"3\", \"4\", \"6\"],\n",
    "        #                   ncols=2)\n",
    "        ax.coastlines(alpha=0.5)\n",
    "        # ax.gridlines(draw_labels=[\"left\", \"bottom\"])\n",
    "        ax.set_title(f\"{i + 1}\")\n",
    "    fig.suptitle(name)\n",
    "    # fig.colorbar(heatmap, ax=axs[:,-2], label=r\"$\\mu(z_\\mathrm{500})$ [m]\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(plots / f\"lswrs-geopotential-heights-{name}.pdf\")\n",
    "\n",
    "\n",
    "for mean_std in means_stds:\n",
    "    plot_geopotential_mean_and_std(*mean_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d54b2-0b86-4cf2-b3db-b66be7ff62af",
   "metadata": {},
   "source": [
    "## Relation of LSWRs to Power Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bbedac-83a3-4ff1-8d60-b205e42793be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "Preprocess turbine data. This takes ~22 min, so prefer loading (cell below)\n",
    "if no changes to the preprocessing are required.\n",
    "\"\"\"\n",
    "\n",
    "paths = list(\n",
    "    pathlib.Path(\"/p/home/jusers/emmerich1/juwels/data/production\").glob(\n",
    "        \"**/*.nc\"\n",
    "    )\n",
    ")\n",
    "print(paths)\n",
    "\n",
    "\n",
    "def remove_outliers(data: xr.Dataset) -> xr.Dataset:\n",
    "    power_rating = float(data.attrs[\"power rating\"].split()[0])\n",
    "    print(power_rating)\n",
    "    # Only use data points where\n",
    "    # - production is lower than power rating\n",
    "    # - production is greater than 0\n",
    "    return data.where(\n",
    "        (\n",
    "            # Find indexes where |P| < power_rating\n",
    "            (abs(data[\"production\"]) < 1.05 * power_rating)\n",
    "            &\n",
    "            # and such where P > 0\n",
    "            (data[\"production\"] > 0)\n",
    "        ),\n",
    "        drop=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# Contains the turbine name and the production\n",
    "turbines: dict[str, xr.Dataset] = {\n",
    "    path.name: remove_outliers(xr.open_dataset(path)) for path in paths\n",
    "}\n",
    "\n",
    "for name, data in turbines.items():\n",
    "    data.to_netcdf(\n",
    "        f\"/p/home/jusers/emmerich1/juwels/data/production-cleaned-for-analysis/{name}.nc\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8c5a3-ea04-4998-b8a0-a72134768fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open preprocessed turbine data if available\n",
    "paths = list(\n",
    "    pathlib.Path(\n",
    "        \"/p/home/jusers/emmerich1/juwels/data/production-cleaned-for-analysis\"\n",
    "    ).glob(\"**/*.nc\")\n",
    ")\n",
    "# Contains the turbine name and the production\n",
    "turbines: dict[str, xr.Dataset] = {\n",
    "    path.name: xr.open_dataset(path) for path in paths\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255dd850-2a2c-4df7-998d-96e1c2812646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import dataclasses\n",
    "import datetime\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class PowerPerMode:\n",
    "    label: int\n",
    "    measurements: list[int] = dataclasses.field(default_factory=list)\n",
    "    sum: list[float] = dataclasses.field(default_factory=list)\n",
    "    mean: list[float] = dataclasses.field(default_factory=list)\n",
    "    std: list[float] = dataclasses.field(default_factory=list)\n",
    "    normalized_mean: list[float] = dataclasses.field(default_factory=list)\n",
    "    normalized_std: list[float] = dataclasses.field(default_factory=list)\n",
    "\n",
    "\n",
    "def get_power_per_lswr(data: xr.Dataset) -> dict[int, PowerPerMode]:\n",
    "    modes = a6.modes.methods.determine_lifetimes_of_modes(data)\n",
    "    dates = [xr.DataArray(list(mode.get_dates())) for mode in modes]\n",
    "\n",
    "    power_per_mode = {\n",
    "        mode.label: PowerPerMode(label=mode.label) for mode in modes\n",
    "    }\n",
    "\n",
    "    for i, (name, turbine) in enumerate(turbines.items()):\n",
    "        print(f\"{data.name}: {i}/{len(turbines)}\", end=\"\\r\")\n",
    "        power_rating = float(turbine.attrs[\"power rating\"].split()[0])\n",
    "\n",
    "        # Resample to daily production and calculate sum, relative mean and std\n",
    "        resampled = turbine[\"production\"].resample({\"time\": \"1d\"}, skipna=True)\n",
    "        daily_sum = resampled.sum(skipna=True)\n",
    "        daily_mean = resampled.mean(skipna=True)\n",
    "        daily_mean_normalized = daily_mean / power_rating\n",
    "        daily_std = resampled.std(skipna=True)\n",
    "        daily_std_normalized = daily_std / power_rating\n",
    "\n",
    "        for mode, date in zip(modes, dates, strict=True):\n",
    "            mode_power = power_per_mode[mode.label]\n",
    "\n",
    "            # Get time steps of production where LSWR appeared\n",
    "            intersection = sorted(set(daily_sum.time.values) & set(date.values))\n",
    "\n",
    "            # if not intersection:\n",
    "            #     print(f\"WARNING: empty intersection for {name} and mode {mode.label}\")\n",
    "            #     continue\n",
    "\n",
    "            # Count number of days that contribute to the results\n",
    "            mode_power.measurements.append(len(intersection))\n",
    "\n",
    "            # Select time steps of LSWR appearance and calculate sum\n",
    "            total = daily_sum.sel(time=intersection)\n",
    "            mode_power.sum.extend(total.values.flatten().tolist())\n",
    "\n",
    "            # Select time steps of LSWR appearance and calculate mean\n",
    "            mean = daily_mean.sel(time=intersection)\n",
    "            mean_normalized = daily_mean_normalized.sel(time=intersection)\n",
    "            mode_power.mean.extend(mean.values.flatten().tolist())\n",
    "            mode_power.normalized_mean.extend(\n",
    "                mean_normalized.values.flatten().tolist()\n",
    "            )\n",
    "\n",
    "            # Select time steps of LSWR appearance and calculate std\n",
    "            std = daily_std.sel(time=intersection)\n",
    "            std_normalized = daily_std_normalized.sel(time=intersection)\n",
    "            mode_power.std.extend(std.values.flatten().tolist())\n",
    "            mode_power.normalized_std.extend(\n",
    "                std_normalized.values.flatten().tolist()\n",
    "            )\n",
    "    return power_per_mode\n",
    "\n",
    "\n",
    "power_per_method = {lswr.name: get_power_per_lswr(lswr) for lswr in lswrs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a36083-08ce-4b97-82ad-bc29f95f1117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latex_code = []\n",
    "\n",
    "\n",
    "def power_mean_with_std_as_string(stats: list[float]) -> str:\n",
    "    return f\"${np.nanmean(stats) * 100:.2f} \\pm {np.nanstd(stats) * 100:.2f}$\"\n",
    "\n",
    "\n",
    "columns = {\n",
    "    \"$N$\": lambda lswrs: [\n",
    "        np.nansum(results.measurements) for results in lswrs.values()\n",
    "    ],\n",
    "    \"$P_{\\mathrm{total}}$ [kW]\": lambda lswrs: [\n",
    "        f\"{int(np.nansum(results.sum)):d}\" for results in lswrs.values()\n",
    "    ],\n",
    "    \"$P^{\\mathrm{mean}}_{\\mathrm{normalized}}$ [\\%]\": lambda lswrs: [\n",
    "        power_mean_with_std_as_string(results.normalized_mean)\n",
    "        for results in lswrs.values()\n",
    "    ],\n",
    "    \"$P^{\\mathrm{std}}_{\\mathrm{normalized}}$ [\\%]\": lambda lswrs: [\n",
    "        power_mean_with_std_as_string(results.normalized_std)\n",
    "        for results in lswrs.values()\n",
    "    ],\n",
    "}\n",
    "\n",
    "reform = {\n",
    "    (name, column): func(method)\n",
    "    for name, method in power_per_method.items()\n",
    "    for column, func in columns.items()\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(reform)\n",
    "\n",
    "# Add 1 to start indexing at 1 to be conform with LSWR labels\n",
    "df.index += 1\n",
    "\n",
    "code = df.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "    label=\"production-per-lswr-per-method\",\n",
    "    caption=f\"Power production for the resulting LSWRs.\",\n",
    ")\n",
    "\n",
    "\n",
    "with open(\n",
    "    \"/p/home/jusers/emmerich1/juwels/code/a6/notebooks/power-production-table.tex\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(code)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ad6df-3d27-4981-ad06-7c9e391436a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a6-cuda",
   "language": "python",
   "name": "a6-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
