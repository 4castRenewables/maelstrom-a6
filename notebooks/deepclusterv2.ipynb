{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DeepClusterV2 results\n",
    "\n",
    "This notebook analyzes the results of the DeepClusterV2 (DCv2) algorithm.\n",
    "\n",
    "The result of DCv2 is a sequence of labels that reflect cluster assignments.\n",
    "Since we make use of timeseries weather data, theses assignments reflect large-scale weather regimes (LSWRs).\n",
    "\n",
    "The goal is to analyze the statistics of each LSWR, i.e. \n",
    "\n",
    "* Abundance, i.e. how often it occurs\n",
    "* Duration of occurrence\n",
    "\n",
    "#### Main results\n",
    "\n",
    "![Cluster embeddings projected into 2-D space using t-SNE](./plots/dcv2-30-clusters-2d.png)\n",
    "\n",
    "![Cluster time series](./plots/dcv2-30-clusters-time-series.png)\n",
    "\n",
    "![Cluster durations](./plots/dcv2-30-clusters-duration.png)\n",
    "\n",
    "* Mean duration of LSWRs varies from 1 day to 2 days.\n",
    "* Some LSWRs show a large variance in duration.\n",
    "* Most LSWRs have a standard deviation of ~ 12 hours.\n",
    "* LSWR 3 and 25 never occur longer than 1 day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import Iterator\n",
    "\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "import matplotlib as mpl\n",
    "import openTSNE\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import a6\n",
    "\n",
    "COLORS = {\n",
    "    -1: \"#000000\",\n",
    "    0: \"#FFFF00\",\n",
    "    1: \"#1CE6FF\",\n",
    "    2: \"#FF34FF\",\n",
    "    3: \"#FF4A46\",\n",
    "    4: \"#008941\",\n",
    "    5: \"#006FA6\",\n",
    "    6: \"#A30059\",\n",
    "    7: \"#FFDBE5\",\n",
    "    8: \"#7A4900\",\n",
    "    9: \"#0000A6\",\n",
    "    10: \"#63FFAC\",\n",
    "    11: \"#B79762\",\n",
    "    12: \"#004D43\",\n",
    "    13: \"#8FB0FF\",\n",
    "    14: \"#997D87\",\n",
    "    15: \"#5A0007\",\n",
    "    16: \"#809693\",\n",
    "    17: \"#FEFFE6\",\n",
    "    18: \"#1B4400\",\n",
    "    19: \"#4FC601\",\n",
    "    20: \"#3B5DFF\",\n",
    "    21: \"#4A3B53\",\n",
    "    22: \"#FF2F80\",\n",
    "    23: \"#61615A\",\n",
    "    24: \"#BA0900\",\n",
    "    25: \"#6B7900\",\n",
    "    26: \"#00C2A0\",\n",
    "    27: \"#FFAA92\",\n",
    "    28: \"#FF90C9\",\n",
    "    29: \"#B903AA\",\n",
    "    30: \"#D16100\",\n",
    "    31: \"#DDEFFF\",\n",
    "    32: \"#000035\",\n",
    "    33: \"#7B4F4B\",\n",
    "    34: \"#A1C299\",\n",
    "    35: \"#300018\",\n",
    "    36: \"#0AA6D8\",\n",
    "    37: \"#013349\",\n",
    "    38: \"#00846F\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for a specific epoch\n",
    "\n",
    "Loads \n",
    "\n",
    "* Centroid positions in embedding space\n",
    "* Indexes of the samples that were used as centroids in that epoch\n",
    "* Cluster assignments\n",
    "* Indexes of the data samples in the dataset\n",
    "* Distances of the samples to the cluster centroids in embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"/home/fabian/data/8080567\")\n",
    "epoch = 1199\n",
    "\n",
    "\n",
    "def _load_tensor_file(name, epoch: int | None = None):\n",
    "    epoch = \"\" if epoch is None else f\"epoch-{epoch}-\"\n",
    "    return torch.load(\n",
    "        path / f\"tensors/{epoch}{name}\", map_location=torch.device(\"cpu\")\n",
    "    )\n",
    "\n",
    "\n",
    "centroids = _load_tensor_file(\"centroids.pt\", epoch=epoch)\n",
    "centroid_indexes = _load_tensor_file(\"centroid-indexes.pt\", epoch=epoch)\n",
    "assignments = _load_tensor_file(\"assignments.pt\", epoch=epoch)\n",
    "embeddings = _load_tensor_file(\"embeddings.pt\", epoch=epoch)\n",
    "indexes = _load_tensor_file(\"indexes.pt\", epoch=epoch)\n",
    "distances = _load_tensor_file(\"distances.pt\", epoch=epoch)\n",
    "\n",
    "with open(path / \"image-samples.yaml\") as f:\n",
    "    sample_indexes = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order centroid indexes\n",
    "\n",
    "Order the centroid indexes to allow using them for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique orders the tensor\n",
    "centroid_indexes = centroid_indexes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many samples are unassigned?\n",
    "\n",
    "When training on multiple GPUs, it might happen that some samples don't get processed and remain unassigned. \n",
    "\n",
    "> _Note:_ Controlled by `config.DATA.TRAIN.DROP_LAST`. If `True`, each GPU processes `floor(n_samples / n_gpus)` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_unassigend_samples(labels: torch.Tensor) -> int:\n",
    "    unassigned_sample_indexes = (labels == -1).nonzero(as_tuple=True)[0]\n",
    "    n_unassigned_samples = len(unassigned_sample_indexes)\n",
    "    return n_unassigned_samples\n",
    "\n",
    "\n",
    "get_number_of_unassigend_samples(assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the index of the crops used for the last iteration\n",
    "\n",
    "DCv2 alternates the crops used for K-means clustering at each iteration. Hence, the embeddings saved to disk will be non-zero only at the index of the crop index.\n",
    "\n",
    "E.g. if `n_crops=3` is used, and K-means is run 4 times, the index of the crops used for the last iteration will be 1.\n",
    "(First iteration, `i_crops=0`, second iteration `i_crops=1`, and so forth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_of_crop(embs: torch.Tensor) -> int:\n",
    "    for i in range(embs.shape[0]):\n",
    "        # The embeddings are all zeros, except for the\n",
    "        # index of the crops used for the last iteration.\n",
    "        if torch.count_nonzero(embs[i]) > 0:\n",
    "            return i\n",
    "    raise ValueError(\"All embeddings are zero: %s\", embs)\n",
    "\n",
    "\n",
    "# j defines the index of the crops used for the last iteration.\n",
    "j = get_index_of_crop(embeddings[-1])\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use t-SNE to project the sample positions from embedding space to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_tsne(\n",
    "    embeddings: torch.Tensor, centroids_: torch.Tensor\n",
    ") -> Iterator[tuple[tuple[float, float], tuple[float, float]]]:\n",
    "    result = openTSNE.TSNE().fit(embeddings.cpu())\n",
    "    return zip(*result), zip(*result[centroids_])\n",
    "\n",
    "\n",
    "(x, y), (x_centroids, y_centroids) = _fit_tsne(\n",
    "    embeddings[-1][j], centroids_=centroid_indexes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 2-D embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_colors(tensor: torch.Tensor | list[str | int]) -> list[str]:\n",
    "    return [COLORS[int(i)] for i in tensor]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "colors = _get_colors(assignments[-1])\n",
    "centroids = assignments[-1][centroid_indexes]\n",
    "colors_centroids = _get_colors(centroids)\n",
    "ax.scatter(x, y, c=colors, s=1)\n",
    "ax.scatter(\n",
    "    x_centroids,\n",
    "    y_centroids,\n",
    "    facecolor=colors_centroids,\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1,\n",
    "    s=20,\n",
    "    marker=\"+\",\n",
    ")\n",
    "ax.legend()\n",
    "plt.savefig(\"./plots/dcv2-30-clusters-2d.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the time series of the first `N` cluster assignments per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = assignments[-1][:364]\n",
    "reshaped = subset.reshape((-1, 7))\n",
    "colors = _get_colors(subset)\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "    \"Custom cmap\", colors, len(colors)\n",
    ")\n",
    "plt.pcolormesh(reshaped, cmap=cmap)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.savefig(\"./plots/dcv2-30-clusters-time-series.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate statstics of the cluster assignments (LSWRs)\n",
    "\n",
    "Get all occurrences of a LSWR (cluster label) in the time series and calculate all statstics for its occurrences:\n",
    "\n",
    "* Total abundance\n",
    "* Mean duration (with standard deviation)\n",
    "* Median duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_and_end_date_of_samples(\n",
    "    samples: dict,\n",
    ") -> tuple[datetime.datetime, datetime.datetime]:\n",
    "    def to_datetime(date: str) -> datetime.datetime:\n",
    "        return datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "\n",
    "    first = samples[0]\n",
    "    last = samples[list(sample_indexes.keys())[-1]]\n",
    "    regex = re.compile(r\"([0-9]{4}-[0-9]{2}-[0-9]{2})T?\")\n",
    "    [first_date_str] = regex.findall(first)\n",
    "    [last_date_str] = regex.findall(last)\n",
    "    return to_datetime(first_date_str), to_datetime(last_date_str)\n",
    "\n",
    "\n",
    "start_date, end_date = get_start_and_end_date_of_samples(sample_indexes)\n",
    "\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq=\"1D\")\n",
    "\n",
    "labels = xr.DataArray(\n",
    "    data=assignments[-1].numpy(), coords={\"time\": dates}, dims=[\"time\"]\n",
    ")\n",
    "\n",
    "modes = a6.modes.methods.determine_lifetimes_of_modes(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the calculated statistics for a random LSWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes[1].statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the mean duration of all LSWRs in the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = _get_colors(range(modes.size))\n",
    "a6.plotting.modes.plot_modes_durations(\n",
    "    modes, colors=colors, start_at_index_0=True\n",
    ")\n",
    "\n",
    "plt.savefig(\"./plots/dcv2-30-clusters-duration.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network-tBjmFLwY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
