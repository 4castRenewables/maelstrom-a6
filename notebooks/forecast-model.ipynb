{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb0cb71-eb0b-44ab-8a82-e4442f397eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dataclasses\n",
    "import logging\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import xarray as xr\n",
    "\n",
    "import a6\n",
    "import a6.datasets.coordinates as _coordinates\n",
    "import a6.datasets.variables as _variables\n",
    "import a6.utils as utils\n",
    "\n",
    "WORKER_ID = 4\n",
    "\n",
    "utils.logging.create_logger(\n",
    "    global_rank=WORKER_ID,\n",
    "    local_rank=WORKER_ID,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"notebook\")\n",
    "\n",
    "\n",
    "turbine_data_dir = pathlib.Path(\n",
    "    \"/p/home/jusers/emmerich1/juwels/data/production\"\n",
    ")\n",
    "preprocessed_data_dir = pathlib.Path(\n",
    "    \"/p/home/jusers/emmerich1/juwels/data/production-preprocessed\"\n",
    ")\n",
    "results_dir = pathlib.Path(\"/p/project/deepacf/emmerich1/data/forecast-errors\")\n",
    "\n",
    "turbine_files = a6.utils.paths.list_files(\n",
    "    turbine_data_dir, pattern=\"**/*.nc\", recursive=True\n",
    ")\n",
    "\n",
    "plots = pathlib.Path(\"/p/project/deepacf/emmerich1/plots\")\n",
    "\n",
    "results = xr.open_dataset(\n",
    "    \"/p/project/deepacf/emmerich1/data/pca_kpca_kmeans_lswrs_29_40.nc\"\n",
    ")\n",
    "results_40 = results.sel(k=40)\n",
    "gwl = xr.open_dataset(\n",
    "    \"/p/home/jusers/emmerich1/juwels/code/a6/src/tests/data/gwl.nc\"\n",
    ")\n",
    "dcv2 = xr.open_dataset(\"/p/project/deepacf/emmerich1/data/dcv2-lswrs.nc\")\n",
    "\n",
    "lswrs = [None, gwl[\"GWL\"], results_40[\"PCA\"], results_40[\"kPCA\"], dcv2[\"DCv2\"]]\n",
    "\n",
    "coordinates: _coordinates.Coordinates = _coordinates.Coordinates()\n",
    "turbine_variables: _variables.Turbine = a6.datasets.variables.Turbine()\n",
    "\n",
    "turbines_with_preprocessed_data = [\n",
    "    path\n",
    "    for path in turbine_files\n",
    "    if (\n",
    "        preprocessed_data_dir / f\"{path.name.replace('.nc', '')}/turbine.nc\"\n",
    "    ).exists()\n",
    "]\n",
    "print(f\"Number of turbines: {len(turbines_with_preprocessed_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9087041",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwl[\"time\"] = dcv2[\"time\"]\n",
    "gwl.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72189815-3a31-4aeb-b742-11fdb4fdfc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Errors:\n",
    "    nmae: float\n",
    "    nrmse: float\n",
    "\n",
    "\n",
    "def _create_forecast(\n",
    "    date: pd.Timestamp,\n",
    "    gs: sklearn.model_selection.GridSearchCV,\n",
    "    weather_data: list[xr.DataArray],\n",
    "    turbine: xr.Dataset,\n",
    "    turbine_variables: _variables.Turbine,\n",
    ") -> tuple[np.ndarray, pd.Timestamp]:\n",
    "    logger.debug(\"Creating forecast for %s\", date)\n",
    "\n",
    "    turbine_sub = a6.datasets.methods.select.select_for_date(\n",
    "        turbine, date=date\n",
    "    )[turbine_variables.production]\n",
    "    y_true = a6.features.methods.reshape.sklearn.transpose(turbine_sub)\n",
    "\n",
    "    if y_true.size < 24:\n",
    "        logger.warning(\n",
    "            (\n",
    "                \"Less than 24 time steps for production data for date=%s, \"\n",
    "                \"returning empty array\"\n",
    "            ),\n",
    "            date,\n",
    "        )\n",
    "        return np.array([]), date\n",
    "\n",
    "    weather_forecast = [\n",
    "        a6.datasets.methods.select.select_for_date(d, date=date)\n",
    "        for d in weather_data\n",
    "    ]\n",
    "    X_forecast = a6.features.methods.reshape.sklearn.transpose(  # noqa: N806\n",
    "        *weather_forecast\n",
    "    )\n",
    "\n",
    "    y_pred = gs.predict(X_forecast)\n",
    "    return y_pred, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f724f5b-e959-480b-acb4-dcd8895a54ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if WORKER_ID is not None and WORKER_ID >= len(turbine_files):\n",
    "    logger.warning(\"Exiting: no file to process\")\n",
    "    raise RuntimeError()\n",
    "\n",
    "\n",
    "result = {}\n",
    "\n",
    "for i, turbine_path in enumerate(turbine_files):\n",
    "    if WORKER_ID is not None and i != WORKER_ID:\n",
    "        continue\n",
    "\n",
    "    logger.info(\n",
    "        \"Processing turbine %i/%i (path=%s)\",\n",
    "        i,\n",
    "        len(turbine_files),\n",
    "        turbine_path,\n",
    "    )\n",
    "\n",
    "    turbine_name = turbine_path.name.replace(\".nc\", \"\")\n",
    "\n",
    "    turbine_path: pathlib.Path = (\n",
    "        preprocessed_data_dir / f\"{turbine_name}/turbine.nc\"\n",
    "    )\n",
    "    pl_path: pathlib.Path = preprocessed_data_dir / f\"{turbine_name}/pl.nc\"\n",
    "    ml_path: pathlib.Path = preprocessed_data_dir / f\"{turbine_name}/ml.nc\"\n",
    "    sfc_path: pathlib.Path = preprocessed_data_dir / f\"{turbine_name}/sfc.nc\"\n",
    "\n",
    "    logger.info(\"Reading preprocessed data\")\n",
    "\n",
    "    try:\n",
    "        turbine = xr.open_dataset(turbine_path)\n",
    "    except FileNotFoundError:\n",
    "        logger.exception(\n",
    "            \"No preprocessed data for turbine %s found in %s\",\n",
    "            turbine_name,\n",
    "            turbine_path,\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    pl = xr.open_dataset(pl_path)\n",
    "    ml = xr.open_dataset(ml_path)\n",
    "    sfc = xr.open_dataset(sfc_path)\n",
    "\n",
    "    power_rating = turbine_variables.read_power_rating(turbine)\n",
    "    logger.info(\"Extracted power rating %i\", power_rating)\n",
    "\n",
    "    # Convert time stamps to dates and create date range\n",
    "    times_as_dates = a6.utils.times.time_steps_as_dates(\n",
    "        turbine, coordinates=coordinates\n",
    "    )\n",
    "    start, end = min(times_as_dates), max(times_as_dates)\n",
    "    dates = pd.date_range(start, end, freq=\"1d\")\n",
    "\n",
    "    logger.info(\n",
    "        \"Simulating forecast errors for LSWRS %s for date range %s to %s\",\n",
    "        lswrs,\n",
    "        start,\n",
    "        end,\n",
    "    )\n",
    "\n",
    "    forecasts = {}\n",
    "\n",
    "    for lswr in lswrs:\n",
    "        lswr_name = \"Default\" if lswr is None else lswr.name\n",
    "\n",
    "        logger.info(\"Handling LSWR %s\", lswr_name)\n",
    "\n",
    "        outfile: pathlib.Path = (\n",
    "            results_dir / f\"{turbine_name}-forecast-errors-lswr-{lswr_name}.nc\"\n",
    "        )\n",
    "\n",
    "        if outfile.exists():\n",
    "            logger.warning(\n",
    "                \"Skipping %s since outfile already exists at %s\",\n",
    "                turbine_path,\n",
    "                outfile,\n",
    "            )\n",
    "\n",
    "        data = (\n",
    "            [ml[var] for var in ml.data_vars]\n",
    "            + [sfc[var] for var in sfc.data_vars]\n",
    "            + [pl[var] for var in pl.data_vars]\n",
    "        )\n",
    "        categorical_features = [False for _ in enumerate(data)]\n",
    "\n",
    "        if lswr is not None:\n",
    "            lswr_labels = lswr.sel(time=turbine[coordinates.time], method=\"pad\")\n",
    "            data.append(lswr_labels)\n",
    "            categorical_features.append(True)\n",
    "\n",
    "        logger.info(\n",
    "            \"Preparing input data for variables %s\", [d.name for d in data]\n",
    "        )\n",
    "\n",
    "        X = a6.features.methods.reshape.sklearn.transpose(*data)  # noqa: N806\n",
    "        y = a6.features.methods.reshape.sklearn.transpose(\n",
    "            turbine[turbine_variables.production]\n",
    "        )\n",
    "\n",
    "        (  # noqa: N806\n",
    "            X_train,\n",
    "            _,\n",
    "            y_train,\n",
    "            _,\n",
    "        ) = sklearn.model_selection.train_test_split(X, y, train_size=1 / 3)\n",
    "\n",
    "        logger.info(\n",
    "            \"Train dataset size is %i hours (~%i days)\",\n",
    "            y_train.size,\n",
    "            y_train.size // 24,\n",
    "        )\n",
    "\n",
    "        logger.info(\"Fitting model with GridSearchCV\")\n",
    "\n",
    "        param_grid = {\n",
    "            \"learning_rate\": [0.03, 0.05, 0.07, 0.1],\n",
    "            \"l2_regularization\": [0.0, 1.0, 3.0, 5.0, 7.0],\n",
    "            \"max_iter\": [200, 300, 500],\n",
    "            \"max_depth\": [15, 37, 63, 81],\n",
    "            \"min_samples_leaf\": [23, 48, 101, 199],\n",
    "            \"categorical_features\": [categorical_features],\n",
    "        }\n",
    "        n_jobs = int(a6.utils.get_cpu_count())\n",
    "\n",
    "        gs = sklearn.model_selection.GridSearchCV(\n",
    "            estimator=ensemble.HistGradientBoostingRegressor(\n",
    "                loss=\"squared_error\"\n",
    "            ),\n",
    "            param_grid=param_grid,\n",
    "            scoring=sklearn.metrics.make_scorer(\n",
    "                a6.training.metrics.turbine.calculate_nrmse,\n",
    "                greater_is_better=False,\n",
    "                power_rating=power_rating,\n",
    "            ),\n",
    "            # 10-fold CV\n",
    "            cv=10,\n",
    "            refit=True,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "        gs = gs.fit(X=X_train, y=y_train.ravel())\n",
    "\n",
    "        for date in dates:\n",
    "            if lswr_name in forecasts:\n",
    "                break\n",
    "\n",
    "            forecast, date = _create_forecast(\n",
    "                date=date,\n",
    "                gs=gs,\n",
    "                weather_data=data,\n",
    "                turbine=turbine,\n",
    "                turbine_variables=turbine_variables,\n",
    "            )\n",
    "\n",
    "            if forecast.size != 0:\n",
    "                forecasts[lswr_name] = (forecast, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b80439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "forecasts_default = forecasts.pop(\"none\")\n",
    "forecasts[\"Default\"] = forecasts_default\n",
    "\n",
    "joblib.dump(\n",
    "    forecasts, \"/p/project/deepacf/emmerich1/data/forecasts-per-method.joblib\"\n",
    ")\n",
    "\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3d270-8f85-4ba4-b3c6-6054ee52e368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "forecasts = joblib.load(\n",
    "    \"/p/project/deepacf/emmerich1/data/forecasts-per-method.joblib\"\n",
    ")\n",
    "\n",
    "turbine_path = turbine_files[WORKER_ID]\n",
    "turbine_name = turbine_path.name.replace(\".nc\", \"\")\n",
    "turbine_path: pathlib.Path = (\n",
    "    preprocessed_data_dir / f\"{turbine_name}/turbine.nc\"\n",
    ")\n",
    "turbine = xr.open_dataset(turbine_path)\n",
    "print(turbine)\n",
    "\n",
    "forecast, date = forecasts[\"PCA\"]\n",
    "x = list(range(forecast.size))\n",
    "xticklabels = [\n",
    "    s.strftime(\"%H:%M\")\n",
    "    for s in pd.date_range(start=\"2000-01-01\", end=\"2000-01-02\", freq=\"1h\")\n",
    "][:-1]\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "actual = a6.datasets.methods.select.select_for_date(turbine, date=date)[\n",
    "    turbine_variables.production\n",
    "]\n",
    "\n",
    "plt.plot(x, actual, label=\"Production\", color=\"black\", linestyle=\"--\")\n",
    "\n",
    "plt.plot(\n",
    "    x, forecasts[\"Default\"][0], label=\"Default\", color=\"black\", linestyle=\":\"\n",
    ")\n",
    "\n",
    "for method, (forecast, _) in forecasts.items():\n",
    "    if method == \"Default\":\n",
    "        continue\n",
    "    plt.plot(x, forecast, label=method)\n",
    "\n",
    "plt.xticks()\n",
    "plt.legend(ncol=3)\n",
    "plt.ylabel(\"$P$ [kW]\")\n",
    "\n",
    "plt.xticks(x, xticklabels, rotation=45)\n",
    "plt.xlabel(\"time\")\n",
    "\n",
    "plt.xlim(-0.5, 24)\n",
    "plt.savefig(plots / \"forecasts-per-method.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7db5a-33a8-42d6-9916-1515e07ce31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = []\n",
    "\n",
    "for i, turbine_path in enumerate(turbines_with_preprocessed_data):\n",
    "    turbine = xr.open_dataset(turbine_path)\n",
    "    lon, lat = (\n",
    "        turbine[\"longitude\"].values.tolist(),\n",
    "        turbine[\"latitude\"].values.tolist(),\n",
    "    )\n",
    "    coordinates.append((lon, lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406aa8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shapereader\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, edgecolor=\"black\", facecolor=\"none\", linewidth=1)\n",
    "\n",
    "# get country borders\n",
    "resolution = \"10m\"\n",
    "category = \"cultural\"\n",
    "name = \"admin_1_states_provinces\"\n",
    "shpfilename = shapereader.natural_earth(resolution, category, name)\n",
    "adm1_shapes = list(shapereader.Reader(shpfilename).geometries())\n",
    "\n",
    "\n",
    "x, y = [x[0] for x in coordinates], [x[1] for x in coordinates]\n",
    "ax.scatter(\n",
    "    x,\n",
    "    y,\n",
    "    marker=\"1\",\n",
    "    s=250,\n",
    "    c=[a6.plotting._colors.LABEL_COLORS[i] for i in range(len(coordinates))],\n",
    ")\n",
    "\n",
    "# Just plotted to avoid calling `ax.set_extent()`, which crashes the kernel\n",
    "ax.scatter(\n",
    "    [10.75, 15.0, 10.75, 15.0],  # longitudes\n",
    "    [51.75, 51.75, 54.0, 54.0],  # latitudes\n",
    "    alpha=0,\n",
    ")\n",
    "\n",
    "ax.add_geometries(\n",
    "    adm1_shapes,\n",
    "    ccrs.PlateCarree(),\n",
    "    edgecolor=\"black\",\n",
    "    facecolor=\"gray\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax.gridlines(\n",
    "    crs=ccrs.PlateCarree(),\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    linestyle=\":\",\n",
    "    draw_labels=[\"left\", \"bottom\"],\n",
    ")\n",
    "\n",
    "plt.savefig(plots / \"turbine-positions.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0707da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_turbine_data(path: pathlib.Path):\n",
    "    d = xr.open_dataset(path)\n",
    "    lat, lon = float(d[\"latitude\"]), float(d[\"longitude\"])\n",
    "    altitude = float(d[\"level\"])\n",
    "    power_rating = float(d.attrs[\"power rating\"].split(\" \")[0]) * 1e-3\n",
    "    hub_height = float(d.attrs[\"hub height\"].split(\" \")[0])\n",
    "    start, end = (\n",
    "        utils.times.numpy_datetime64_to_datetime(d[\"time\"][0].values).strftime(\n",
    "            \"%Y-%m-%d\"\n",
    "        ),\n",
    "        utils.times.numpy_datetime64_to_datetime(d[\"time\"][-1].values).strftime(\n",
    "            \"%Y-%m-%d\"\n",
    "        ),\n",
    "    )\n",
    "    return [\n",
    "        f\"{lat:.1f}\",\n",
    "        f\"{lon:.1f}\",\n",
    "        f\"{altitude:.1f}\",\n",
    "        f\"{hub_height:.0f}\",\n",
    "        f\"{power_rating:.1f}\",\n",
    "        start,\n",
    "        end,\n",
    "    ]\n",
    "\n",
    "\n",
    "data = [extract_turbine_data(path) for path in turbines_with_preprocessed_data]\n",
    "df = pd.DataFrame(\n",
    "    data=data,\n",
    "    columns=[\n",
    "        \"Lat.\",\n",
    "        \"Lon.\",\n",
    "        \"Alt. [m]\",\n",
    "        \"Hub height [m]\",\n",
    "        \"Power rating [MW]\",\n",
    "        \"Start date\",\n",
    "        \"End date\",\n",
    "    ],\n",
    ")\n",
    "code = df.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "    label=\"turbines\",\n",
    "    index=False,\n",
    "    column_format=\"rrrrrcc\",\n",
    "    caption=\"\"\"\n",
    "    Properties of the wind turbines.\n",
    "\tShown are the geographical position (latitude, longitude, altitude),\n",
    "\thub height and power rating (or nominal power output),\n",
    "\tand start and end date of the available power production data\n",
    "\tof the respective turbine.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "with open(\n",
    "    \"/p/home/jusers/emmerich1/juwels/code/a6/notebooks/turbines-table.tex\", \"w\"\n",
    ") as f:\n",
    "    f.write(code)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import datetime\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ErrorsPerLswr:\n",
    "    label: int\n",
    "    measurements: list[int] = dataclasses.field(default_factory=list)\n",
    "    nmae: list[int] = dataclasses.field(default_factory=list)\n",
    "    nrmse: list[int] = dataclasses.field(default_factory=list)\n",
    "\n",
    "\n",
    "def get_errors_per_lswr(data: xr.Dataset) -> dict[int, ErrorsPerLswr]:\n",
    "    modes = a6.modes.methods.determine_lifetimes_of_modes(data)\n",
    "    dates = [xr.DataArray(list(mode.get_dates())) for mode in modes]\n",
    "\n",
    "    errors_per_mode = {\n",
    "        mode.label: ErrorsPerLswr(label=mode.label) for mode in modes\n",
    "    }\n",
    "\n",
    "    for i, turbine in enumerate(errors):\n",
    "        print(f\"{data.name}: {i}/{len(errors)}\", end=\"\\r\")\n",
    "\n",
    "        for mode, date in zip(modes, dates, strict=True):\n",
    "            mode_power = errors_per_mode[mode.label]\n",
    "\n",
    "            # Get time steps of production where LSWR appeared\n",
    "            intersection = sorted(set(turbine.time.values) & set(date.values))\n",
    "\n",
    "            if not intersection:\n",
    "                logger.warning(\n",
    "                    f\"{data.name}: empty intersection for {i} and mode {mode.label}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            turbine_sub = turbine.sel(time=intersection, lswr_method=\"Default\")\n",
    "\n",
    "            # Count number of days that contribute to the results\n",
    "            mode_power.measurements.append(len(intersection))\n",
    "\n",
    "            # Select time steps of LSWR appearance and calculate mean\n",
    "            nmae = turbine_sub[\"nmae\"]\n",
    "            mode_power.nmae.extend(nmae.values.flatten().tolist())\n",
    "\n",
    "            nrmse = turbine_sub[\"nrmse\"]\n",
    "            mode_power.nrmse.extend(nrmse.values.flatten().tolist())\n",
    "\n",
    "    return errors_per_mode\n",
    "\n",
    "\n",
    "errors_per_method = {\n",
    "    lswr.name: get_errors_per_lswr(lswr) for lswr in lswrs if lswr is not None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def errors_mean_with_std_as_string(stats: list[float]) -> str:\n",
    "    return f\"${np.nanmean(stats) * 100:.2f} \\pm {np.nanstd(stats) * 100:.2f}$\"\n",
    "\n",
    "\n",
    "latex_code = []\n",
    "columns = {\n",
    "    \"$N$\": lambda lswrs: [\n",
    "        np.nansum(results.measurements) for results in lswrs.values()\n",
    "    ],\n",
    "    \"NMAE [\\%]\": lambda lswrs: [\n",
    "        errors_mean_with_std_as_string(results.nmae)\n",
    "        for results in lswrs.values()\n",
    "    ],\n",
    "    \"NRMSE [\\%]\": lambda lswrs: [\n",
    "        errors_mean_with_std_as_string(results.nrmse)\n",
    "        for results in lswrs.values()\n",
    "    ],\n",
    "}\n",
    "\n",
    "reform = {\n",
    "    (name, column): func(method)\n",
    "    for name, method in errors_per_method.items()\n",
    "    for column, func in columns.items()\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(reform)\n",
    "\n",
    "# Add 1 to start indexing at 1 to be conform with LSWR labels\n",
    "df.index += 1\n",
    "\n",
    "code = df.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "    label=\"errors-per-lswr-per-method\",\n",
    "    caption=f\"Normalized MAE and RMSE of the Default model for the resulting LSWRs.\",\n",
    ")\n",
    "\n",
    "\n",
    "with open(\n",
    "    \"/p/home/jusers/emmerich1/juwels/code/a6/notebooks/errors-table.tex\", \"w\"\n",
    ") as f:\n",
    "    f.write(code)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2993a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataclasses\n",
    "import datetime\n",
    "\n",
    "start, end = min(min(turbine.time.values) for turbine in errors), max(\n",
    "    max(turbine.time.values) for turbine in errors\n",
    ")\n",
    "date_range = pd.date_range(start, end, freq=\"1d\")\n",
    "date_range\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ErrorsPerDay:\n",
    "    time: pd.Timestamp\n",
    "    measurements: int = 0\n",
    "    nmae: list[int] = dataclasses.field(default_factory=list)\n",
    "    nrmse: list[int] = dataclasses.field(default_factory=list)\n",
    "\n",
    "\n",
    "def get_errors_per_day(\n",
    "    data: xr.DataArray | None,\n",
    ") -> dict[pd.Timestamp, ErrorsPerDay]:\n",
    "    name = data.name if data is not None else \"Default\"\n",
    "    errors_per_day = {step: ErrorsPerDay(time=step) for step in date_range}\n",
    "\n",
    "    for i, step in enumerate(date_range):\n",
    "        day_errors = errors_per_day[step]\n",
    "\n",
    "        for j, turbine in enumerate(errors):\n",
    "            print(\n",
    "                f\"{name}: day {i}/{len(date_range)}, turbine {j}/{len(errors)}\",\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "\n",
    "            if step not in turbine[\"time\"]:\n",
    "                continue\n",
    "\n",
    "            turbine_sub = turbine.sel(time=step, lswr_method=name)\n",
    "\n",
    "            # Add to counter for turbines that contribute to the results\n",
    "            day_errors.measurements += 1\n",
    "\n",
    "            # Select time steps of LSWR appearance and calculate mean\n",
    "            nmae = turbine_sub[\"nmae\"]\n",
    "            day_errors.nmae.append(nmae.values.tolist())\n",
    "\n",
    "            nrmse = turbine_sub[\"nrmse\"]\n",
    "            day_errors.nrmse.append(nrmse.values.tolist())\n",
    "\n",
    "    return errors_per_day\n",
    "\n",
    "\n",
    "errors_per_day = {\n",
    "    (lswr.name if lswr is not None else \"Default\"): get_errors_per_day(lswr)\n",
    "    for lswr in lswrs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db165a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_rows = 5\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    figsize=(12, 4 * n_rows), nrows=n_rows, ncols=1, sharex=True\n",
    ")\n",
    "\n",
    "means_per_day = []\n",
    "stds_per_day = []\n",
    "\n",
    "attr = \"nmae\"\n",
    "\n",
    "for results in errors_per_day.values():\n",
    "    mean_per_day = (\n",
    "        np.array([np.nanmean(getattr(day, attr)) for day in results.values()])\n",
    "        * 100\n",
    "    )\n",
    "    std_per_day = (\n",
    "        np.array([np.nanstd(getattr(day, attr)) for day in results.values()])\n",
    "        * 100\n",
    "    )\n",
    "\n",
    "    means_per_day.append(mean_per_day)\n",
    "    stds_per_day.append(std_per_day)\n",
    "\n",
    "x_start, x_end = 100, 300\n",
    "\n",
    "global_max = np.nanmax(\n",
    "    [\n",
    "        np.nanmax(m[x_start:x_end] + s[x_start:x_end])\n",
    "        for m, s in zip(means_per_day, stds_per_day)\n",
    "    ]\n",
    ")\n",
    "global_min = np.nanmin(\n",
    "    [\n",
    "        np.nanmin(m[x_start:x_end] - s[x_start:x_end])\n",
    "        for m, s in zip(means_per_day, stds_per_day)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# If global minimum is lower than 2%, set it to 0.\n",
    "# This is used for the ylim in each plot\n",
    "if global_min < 2.0:\n",
    "    global_min = 0.0\n",
    "\n",
    "x = list(range(len(date_range)))\n",
    "\n",
    "for i, (name, results) in enumerate(errors_per_day.items()):\n",
    "    ax = axs[i]\n",
    "\n",
    "    mean_per_day = means_per_day[i]\n",
    "    std_per_day = stds_per_day[i]\n",
    "\n",
    "    all_errs = (\n",
    "        np.array(\n",
    "            [nrmse for day in results.values() for nrmse in getattr(day, attr)]\n",
    "        )\n",
    "        * 100\n",
    "    )\n",
    "    global_mean = np.nanmean(all_errs)\n",
    "    global_std = np.nanstd(all_errs)\n",
    "\n",
    "    ax.plot(\n",
    "        x,\n",
    "        mean_per_day,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        mean_per_day - std_per_day,\n",
    "        mean_per_day + std_per_day,\n",
    "        color=\"gray\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    # Plot global mean and standard deviation\n",
    "    ax.hlines(\n",
    "        y=global_mean,\n",
    "        xmin=-10,\n",
    "        xmax=x[-1] + 10,\n",
    "        linewidth=1,\n",
    "        linestyle=\"--\",\n",
    "        color=\"black\",\n",
    "        label=rf\"$\\mu_\\mathrm{{{attr.upper()}}}^\\mathrm{{global}} = ({global_mean:.2f} \\pm {global_std:.2f})\\,\\%$\",\n",
    "    )\n",
    "\n",
    "    ax.hlines(\n",
    "        y=global_mean + global_std,\n",
    "        xmin=-10,\n",
    "        xmax=x[-1] + 10,\n",
    "        linewidth=1,\n",
    "        linestyle=\":\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "    ax.hlines(\n",
    "        y=global_mean - global_std,\n",
    "        xmin=-10,\n",
    "        xmax=x[-1] + 10,\n",
    "        linewidth=1,\n",
    "        linestyle=\":\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(name)\n",
    "\n",
    "    ax.set_xlim(x_start, x_end)\n",
    "\n",
    "    if i == n_rows - 1:\n",
    "        ax.set_xlabel(\"time\")\n",
    "        xticks = ax.get_xticks()\n",
    "        xticklabels = [\n",
    "            date_range[int(tick)].strftime(\"%Y-%m-%d\") for tick in xticks[1:]\n",
    "        ]\n",
    "        ax.set_xticklabels(xticklabels, rotation=45)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    ax.set_ylabel(rf\"$\\mu_\\mathrm{{{attr.upper()}}}$ [%]\")\n",
    "\n",
    "    ax.set_ylim(global_min * 0.9, global_max * 1.05)\n",
    "    ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(plots / f\"forecast-error-timeseries-per-lswr-method-{attr}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a6-cuda",
   "language": "python",
   "name": "a6-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
