{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb0cb71-eb0b-44ab-8a82-e4442f397eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dataclasses\n",
    "import logging\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import xarray as xr\n",
    "\n",
    "import a6\n",
    "import a6.datasets.coordinates as _coordinates\n",
    "import a6.datasets.variables as _variables\n",
    "import a6.utils as utils\n",
    "import a6.plotting._colors as _colors\n",
    "\n",
    "WORKER_ID = 4\n",
    "\n",
    "utils.logging.create_logger(\n",
    "    global_rank=WORKER_ID,\n",
    "    local_rank=WORKER_ID,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"notebook\")\n",
    "\n",
    "\n",
    "turbine_data_dir = pathlib.Path(\n",
    "    \"/p/home/jusers/emmerich1/juwels/data/production\"\n",
    ")\n",
    "preprocessed_data_dir = pathlib.Path(\n",
    "    \"/p/home/jusers/emmerich1/juwels/data/production-preprocessed-status-filter\"\n",
    ")\n",
    "results_dir = pathlib.Path(\n",
    "    \"/p/project1/deepacf/emmerich1/data/forecast-errors-randomized-labels\"\n",
    ")\n",
    "\n",
    "turbine_files = a6.utils.paths.list_files(\n",
    "    turbine_data_dir, pattern=\"**/*.nc\", recursive=True\n",
    ")\n",
    "\n",
    "turbine_error_files = a6.utils.paths.list_files(\n",
    "    results_dir, pattern=\"*.nc\", recursive=False\n",
    ")\n",
    "turbine_errors = [xr.open_dataset(path) for path in turbine_error_files]\n",
    "\n",
    "plots = pathlib.Path(\"/p/project1/deepacf/emmerich1/plots\")\n",
    "\n",
    "results = xr.open_dataset(\n",
    "    \"/p/project1/deepacf/emmerich1/data/pca_kpca_kmeans_lswrs_30_40.nc\"\n",
    ")\n",
    "n_lswr_categories = 40\n",
    "results_40 = results.sel(k=n_lswr_categories)\n",
    "gwl = xr.open_dataset(\n",
    "    \"/p/home/jusers/emmerich1/juwels/code/a6/src/tests/data/gwl.nc\"\n",
    ")\n",
    "dcv2 = xr.open_dataset(\"/p/project1/deepacf/emmerich1/data/dcv2-lswrs.nc\")\n",
    "\n",
    "lswrs = [\n",
    "    \"Default\",\n",
    "    gwl[\"GWL\"],\n",
    "    results_40[\"PCA\"],\n",
    "    results_40[\"kPCA\"],\n",
    "    dcv2[\"DCv2\"],\n",
    "    \"Random\",\n",
    "]\n",
    "\n",
    "coordinates: _coordinates.Coordinates = _coordinates.Coordinates()\n",
    "turbine_variables: _variables.Turbine = a6.datasets.variables.Turbine()\n",
    "\n",
    "turbines_with_preprocessed_data = [\n",
    "    path\n",
    "    for path in turbine_files\n",
    "    if (\n",
    "        preprocessed_data_dir / f\"{path.name.replace('.nc', '')}/turbine.nc\"\n",
    "    ).exists()\n",
    "]\n",
    "print(f\"Number of turbines: {len(turbines_with_preprocessed_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b02bc83-cc9a-4230-b742-a5dfebf99eda",
   "metadata": {},
   "source": [
    "## Create single forecast with different LSWRs as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72189815-3a31-4aeb-b742-11fdb4fdfc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Errors:\n",
    "    nmae: float\n",
    "    nrmse: float\n",
    "\n",
    "\n",
    "def _create_forecast(\n",
    "    date: pd.Timestamp,\n",
    "    gs: sklearn.model_selection.GridSearchCV,\n",
    "    weather_data: list[xr.DataArray],\n",
    "    turbine: xr.Dataset,\n",
    "    turbine_variables: _variables.Turbine,\n",
    ") -> tuple[np.ndarray, pd.Timestamp]:\n",
    "    logger.debug(\"Creating forecast for %s\", date)\n",
    "\n",
    "    turbine_sub = a6.datasets.methods.select.select_for_date(\n",
    "        turbine, date=date\n",
    "    )[turbine_variables.production]\n",
    "    y_true = a6.features.methods.reshape.sklearn.transpose(turbine_sub)\n",
    "\n",
    "    if y_true.size < 24:\n",
    "        logger.warning(\n",
    "            (\n",
    "                \"Less than 24 time steps for production data for date=%s, \"\n",
    "                \"returning empty array\"\n",
    "            ),\n",
    "            date,\n",
    "        )\n",
    "        return np.array([]), date\n",
    "\n",
    "    weather_forecast = [\n",
    "        a6.datasets.methods.select.select_for_date(d, date=date)\n",
    "        for d in weather_data\n",
    "    ]\n",
    "    X_forecast = a6.features.methods.reshape.sklearn.transpose(  # noqa: N806\n",
    "        *weather_forecast\n",
    "    )\n",
    "\n",
    "    y_pred = gs.predict(X_forecast)\n",
    "    return y_pred, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f724f5b-e959-480b-acb4-dcd8895a54ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if WORKER_ID is not None and WORKER_ID >= len(turbine_files):\n",
    "    logger.warning(\"Exiting: no file to process\")\n",
    "    raise RuntimeError()\n",
    "\n",
    "\n",
    "result = {}\n",
    "\n",
    "for i, turbine_path in enumerate(turbine_files):\n",
    "    if WORKER_ID is not None and i != WORKER_ID:\n",
    "        continue\n",
    "\n",
    "    logger.info(\n",
    "        \"Processing turbine %i/%i (path=%s)\",\n",
    "        i,\n",
    "        len(turbine_files),\n",
    "        turbine_path,\n",
    "    )\n",
    "\n",
    "    turbine_name = turbine_path.name.replace(\".nc\", \"\")\n",
    "\n",
    "    turbine_path: pathlib.Path = (\n",
    "        preprocessed_data_dir / f\"{turbine_name}/turbine.nc\"\n",
    "    )\n",
    "    pl_path: pathlib.Path = preprocessed_data_dir / f\"{turbine_name}/pl.nc\"\n",
    "    ml_path: pathlib.Path = preprocessed_data_dir / f\"{turbine_name}/ml.nc\"\n",
    "    sfc_path: pathlib.Path = preprocessed_data_dir / f\"{turbine_name}/sfc.nc\"\n",
    "\n",
    "    logger.info(\"Reading preprocessed data\")\n",
    "\n",
    "    try:\n",
    "        turbine = xr.open_dataset(turbine_path)\n",
    "    except FileNotFoundError:\n",
    "        logger.exception(\n",
    "            \"No preprocessed data for turbine %s found in %s\",\n",
    "            turbine_name,\n",
    "            turbine_path,\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    pl = xr.open_dataset(pl_path)\n",
    "    ml = xr.open_dataset(ml_path)\n",
    "    sfc = xr.open_dataset(sfc_path)\n",
    "\n",
    "    power_rating = turbine_variables.read_power_rating(turbine)\n",
    "    logger.info(\"Extracted power rating %i\", power_rating)\n",
    "\n",
    "    # Convert time stamps to dates and create date range\n",
    "    times_as_dates = a6.utils.times.time_steps_as_dates(\n",
    "        turbine, coordinates=coordinates\n",
    "    )\n",
    "    start, end = min(times_as_dates), max(times_as_dates)\n",
    "    dates = pd.date_range(start, end, freq=\"1d\")\n",
    "\n",
    "    logger.info(\n",
    "        \"Simulating forecast errors for LSWRS %s for date range %s to %s\",\n",
    "        lswrs,\n",
    "        start,\n",
    "        end,\n",
    "    )\n",
    "\n",
    "    forecasts = {}\n",
    "\n",
    "    for lswr in lswrs:\n",
    "        if lswr == \"Random\":\n",
    "            logger.warning(\"Skipping Random LSWR labels\")\n",
    "\n",
    "        lswr_name = lswr if isinstance(lswr, str) else lswr.name\n",
    "\n",
    "        logger.info(\"Handling LSWR %s\", lswr_name)\n",
    "\n",
    "        outfile: pathlib.Path = (\n",
    "            results_dir / f\"{turbine_name}-forecast-errors-lswr-{lswr_name}.nc\"\n",
    "        )\n",
    "\n",
    "        if outfile.exists():\n",
    "            logger.warning(\n",
    "                \"Skipping %s since outfile already exists at %s\",\n",
    "                turbine_path,\n",
    "                outfile,\n",
    "            )\n",
    "\n",
    "        data = (\n",
    "            [ml[var] for var in ml.data_vars]\n",
    "            + [sfc[var] for var in sfc.data_vars]\n",
    "            + [pl[var] for var in pl.data_vars]\n",
    "        )\n",
    "        categorical_features = [False for _ in enumerate(data)]\n",
    "\n",
    "        if lswr == \"Default\":\n",
    "            lswr_labels = lswr.sel(time=turbine[coordinates.time], method=\"pad\")\n",
    "            data.append(lswr_labels)\n",
    "            categorical_features.append(True)\n",
    "\n",
    "        logger.info(\n",
    "            \"Preparing input data for variables %s\", [d.name for d in data]\n",
    "        )\n",
    "\n",
    "        X = a6.features.methods.reshape.sklearn.transpose(*data)  # noqa: N806\n",
    "        y = a6.features.methods.reshape.sklearn.transpose(\n",
    "            turbine[turbine_variables.production]\n",
    "        )\n",
    "\n",
    "        (  # noqa: N806\n",
    "            X_train,\n",
    "            _,\n",
    "            y_train,\n",
    "            _,\n",
    "        ) = sklearn.model_selection.train_test_split(X, y, train_size=1 / 3)\n",
    "\n",
    "        logger.info(\n",
    "            \"Train dataset size is %i hours (~%i days)\",\n",
    "            y_train.size,\n",
    "            y_train.size // 24,\n",
    "        )\n",
    "\n",
    "        logger.info(\"Fitting model with GridSearchCV\")\n",
    "\n",
    "        param_grid = {\n",
    "            \"learning_rate\": [0.03, 0.05, 0.07, 0.1],\n",
    "            \"l2_regularization\": [0.0, 1.0, 3.0, 5.0, 7.0],\n",
    "            \"max_iter\": [200, 300, 500],\n",
    "            \"max_depth\": [15, 37, 63, 81],\n",
    "            \"min_samples_leaf\": [23, 48, 101, 199],\n",
    "            \"categorical_features\": [categorical_features],\n",
    "        }\n",
    "        n_jobs = int(a6.utils.get_cpu_count())\n",
    "\n",
    "        gs = sklearn.model_selection.GridSearchCV(\n",
    "            estimator=ensemble.HistGradientBoostingRegressor(\n",
    "                loss=\"squared_error\"\n",
    "            ),\n",
    "            param_grid=param_grid,\n",
    "            scoring=sklearn.metrics.make_scorer(\n",
    "                a6.training.metrics.turbine.calculate_nrmse,\n",
    "                greater_is_better=False,\n",
    "                power_rating=power_rating,\n",
    "            ),\n",
    "            # 10-fold CV\n",
    "            cv=10,\n",
    "            refit=True,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "        gs = gs.fit(X=X_train, y=y_train.ravel())\n",
    "\n",
    "        for date in dates:\n",
    "            if lswr_name in forecasts:\n",
    "                break\n",
    "\n",
    "            forecast, date = _create_forecast(\n",
    "                date=date,\n",
    "                gs=gs,\n",
    "                weather_data=data,\n",
    "                turbine=turbine,\n",
    "                turbine_variables=turbine_variables,\n",
    "            )\n",
    "\n",
    "            if forecast.size != 0:\n",
    "                forecasts[lswr_name] = (forecast, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b80439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "forecasts_default = forecasts.pop(\"none\")\n",
    "forecasts[\"Default\"] = forecasts_default\n",
    "\n",
    "joblib.dump(\n",
    "    forecasts, \"/p/project1/deepacf/emmerich1/data/forecasts-per-method.joblib\"\n",
    ")\n",
    "\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac1775-4ea2-4ed7-8ab0-4a97d85e019e",
   "metadata": {},
   "source": [
    "## Plot forecasts for LSWR inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3d270-8f85-4ba4-b3c6-6054ee52e368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "forecasts = joblib.load(\n",
    "    \"/p/project1/deepacf/emmerich1/data/forecasts-per-method.joblib\"\n",
    ")\n",
    "\n",
    "turbine_path = turbine_files[WORKER_ID]\n",
    "turbine_name = turbine_path.name.replace(\".nc\", \"\")\n",
    "turbine_path: pathlib.Path = (\n",
    "    preprocessed_data_dir / f\"{turbine_name}/turbine.nc\"\n",
    ")\n",
    "turbine = xr.open_dataset(turbine_path)\n",
    "print(turbine)\n",
    "\n",
    "forecast, date = forecasts[\"PCA\"]\n",
    "x = list(range(forecast.size))\n",
    "xticklabels = [\n",
    "    s.strftime(\"%H:%M\")\n",
    "    for s in pd.date_range(start=\"2000-01-01\", end=\"2000-01-02\", freq=\"1h\")\n",
    "][:-1]\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "actual = a6.datasets.methods.select.select_for_date(turbine, date=date)[\n",
    "    turbine_variables.production\n",
    "]\n",
    "\n",
    "plt.plot(x, actual, label=\"Production\", color=\"black\", linestyle=\"--\")\n",
    "\n",
    "plt.plot(\n",
    "    x, forecasts[\"Default\"][0], label=\"Default\", color=\"black\", linestyle=\":\"\n",
    ")\n",
    "\n",
    "for method, (forecast, _) in forecasts.items():\n",
    "    if method == \"Default\":\n",
    "        continue\n",
    "    plt.plot(x, forecast, label=method)\n",
    "\n",
    "plt.xticks()\n",
    "plt.legend(ncol=3)\n",
    "plt.ylabel(\"$P$ [kW]\")\n",
    "\n",
    "plt.xticks(x, xticklabels, rotation=45)\n",
    "plt.xlabel(\"time\")\n",
    "\n",
    "plt.xlim(-0.5, 24)\n",
    "plt.savefig(plots / \"forecasts-per-method.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3b0b5-107a-4f25-81c8-e5f6c3d0f971",
   "metadata": {},
   "source": [
    "## Plot turbine positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7db5a-33a8-42d6-9916-1515e07ce31a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coordinates = []\n",
    "\n",
    "for i, turbine_path in enumerate(turbines_with_preprocessed_data):\n",
    "    turbine = xr.open_dataset(turbine_path)\n",
    "    lon, lat = (\n",
    "        turbine[\"longitude\"].values.tolist(),\n",
    "        turbine[\"latitude\"].values.tolist(),\n",
    "    )\n",
    "    coordinates.append((lon, lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406aa8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shapereader\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, edgecolor=\"black\", facecolor=\"none\", linewidth=1)\n",
    "\n",
    "# get country borders\n",
    "resolution = \"10m\"\n",
    "category = \"cultural\"\n",
    "name = \"admin_1_states_provinces\"\n",
    "shpfilename = shapereader.natural_earth(resolution, category, name)\n",
    "adm1_shapes = list(shapereader.Reader(shpfilename).geometries())\n",
    "\n",
    "\n",
    "x, y = [x[0] for x in coordinates], [x[1] for x in coordinates]\n",
    "ax.scatter(\n",
    "    x,\n",
    "    y,\n",
    "    marker=\"1\",\n",
    "    s=250,\n",
    "    c=[a6.plotting._colors.LABEL_COLORS[i] for i in range(len(coordinates))],\n",
    ")\n",
    "\n",
    "# Just plotted to avoid calling `ax.set_extent()`, which crashes the kernel\n",
    "ax.scatter(\n",
    "    [7.75, 15.0, 7.75, 15.0],  # longitudes\n",
    "    [50.75, 50.75, 56.0, 56.0],  # latitudes\n",
    "    alpha=0,\n",
    ")\n",
    "\n",
    "ax.add_geometries(\n",
    "    adm1_shapes,\n",
    "    ccrs.PlateCarree(),\n",
    "    edgecolor=\"black\",\n",
    "    facecolor=\"gray\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax.gridlines(\n",
    "    crs=ccrs.PlateCarree(),\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    linestyle=\":\",\n",
    "    draw_labels=[\"left\", \"bottom\"],\n",
    ")\n",
    "\n",
    "plt.savefig(plots / \"turbine-positions.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86381242-629e-418b-aa85-cd37f87f05a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summarize turbine properties in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0707da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_turbine_data(path: pathlib.Path):\n",
    "    d = xr.open_dataset(path)\n",
    "    lat, lon = float(d[\"latitude\"]), float(d[\"longitude\"])\n",
    "    altitude = float(d[\"level\"])\n",
    "    power_rating = float(d.attrs[\"power rating\"].split(\" \")[0]) * 1e-3\n",
    "    hub_height = float(d.attrs[\"hub height\"].split(\" \")[0])\n",
    "    start, end = (\n",
    "        utils.times.numpy_datetime64_to_datetime(d[\"time\"][0].values).strftime(\n",
    "            \"%Y-%m-%d\"\n",
    "        ),\n",
    "        utils.times.numpy_datetime64_to_datetime(d[\"time\"][-1].values).strftime(\n",
    "            \"%Y-%m-%d\"\n",
    "        ),\n",
    "    )\n",
    "    return [\n",
    "        f\"{lat:.1f}\",\n",
    "        f\"{lon:.1f}\",\n",
    "        f\"{altitude:.1f}\",\n",
    "        f\"{hub_height:.0f}\",\n",
    "        f\"{power_rating:.1f}\",\n",
    "        start,\n",
    "        end,\n",
    "    ]\n",
    "\n",
    "\n",
    "data = [extract_turbine_data(path) for path in turbines_with_preprocessed_data]\n",
    "df = pd.DataFrame(\n",
    "    data=data,\n",
    "    columns=[\n",
    "        \"Lat.\",\n",
    "        \"Lon.\",\n",
    "        \"Alt. [m]\",\n",
    "        \"Hub height [m]\",\n",
    "        \"Power rating [MW]\",\n",
    "        \"Start date\",\n",
    "        \"End date\",\n",
    "    ],\n",
    ")\n",
    "code = df.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "    label=\"turbines\",\n",
    "    index=False,\n",
    "    column_format=\"rrrrrcc\",\n",
    "    caption=\"\"\"\n",
    "    Properties of the wind turbines.\n",
    "\tShown are the geographical position (latitude, longitude, altitude),\n",
    "\thub height and power rating (or nominal power output),\n",
    "\tand start and end date of the available power production data\n",
    "\tof the respective turbine.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "with open(\n",
    "    \"/p/home/jusers/emmerich1/juwels/code/a6/notebooks/turbines-table.tex\", \"w\"\n",
    ") as f:\n",
    "    f.write(code)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bf141-91f5-4ce5-86f0-4977a202ae1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summarize errors for every LSWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070cbeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import datetime\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ErrorsPerLswr:\n",
    "    label: int\n",
    "    measurements: list[int] = dataclasses.field(default_factory=list)\n",
    "    nmae: list[int] = dataclasses.field(default_factory=list)\n",
    "    nrmse: list[int] = dataclasses.field(default_factory=list)\n",
    "\n",
    "\n",
    "def get_errors_per_lswr(data: xr.Dataset) -> dict[int, ErrorsPerLswr]:\n",
    "    modes = a6.modes.methods.determine_lifetimes_of_modes(data)\n",
    "    dates = [xr.DataArray(list(mode.get_dates())) for mode in modes]\n",
    "\n",
    "    errors_per_mode = {\n",
    "        mode.label: ErrorsPerLswr(label=mode.label) for mode in modes\n",
    "    }\n",
    "\n",
    "    for i, turbine in enumerate(turbine_errors):\n",
    "        print(f\"{data.name}: {i}/{len(turbine_errors)}\", end=\"\\r\")\n",
    "\n",
    "        for mode, date in zip(modes, dates, strict=True):\n",
    "            mode_power = errors_per_mode[mode.label]\n",
    "\n",
    "            # Get time steps of production where LSWR appeared\n",
    "            intersection = sorted(set(turbine.time.values) & set(date.values))\n",
    "\n",
    "            if not intersection:\n",
    "                logger.warning(\n",
    "                    f\"{data.name}: empty intersection for {i} and mode {mode.label}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            turbine_sub = turbine.sel(time=intersection, lswr_method=\"Default\")\n",
    "\n",
    "            # Count number of days that contribute to the results\n",
    "            mode_power.measurements.append(len(intersection))\n",
    "\n",
    "            # Select time steps of LSWR appearance and calculate mean\n",
    "            nmae = turbine_sub[\"nmae\"]\n",
    "            mode_power.nmae.extend(nmae.values.flatten().tolist())\n",
    "\n",
    "            nrmse = turbine_sub[\"nrmse\"]\n",
    "            mode_power.nrmse.extend(nrmse.values.flatten().tolist())\n",
    "\n",
    "    return errors_per_mode\n",
    "\n",
    "\n",
    "errors_per_method = {\n",
    "    lswr.name: get_errors_per_lswr(lswr)\n",
    "    for lswr in lswrs\n",
    "    if isinstance(lswr, xr.DataArray)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46871f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def errors_mean_with_std_as_string(stats: list[float]) -> str:\n",
    "    return f\"${np.nanmean(stats) * 100:.2f} \\pm {np.nanstd(stats) * 100:.2f}$\"\n",
    "\n",
    "\n",
    "latex_code = []\n",
    "columns = {\n",
    "    \"$N$\": lambda lswrs: [\n",
    "        np.nansum(results.measurements) for results in lswrs.values()\n",
    "    ],\n",
    "    \"NMAE [\\%]\": lambda lswrs: [\n",
    "        errors_mean_with_std_as_string(results.nmae)\n",
    "        for results in lswrs.values()\n",
    "    ],\n",
    "    \"NRMSE [\\%]\": lambda lswrs: [\n",
    "        errors_mean_with_std_as_string(results.nrmse)\n",
    "        for results in lswrs.values()\n",
    "    ],\n",
    "}\n",
    "\n",
    "reform = {\n",
    "    (name, column): func(method)\n",
    "    for name, method in errors_per_method.items()\n",
    "    for column, func in columns.items()\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(reform)\n",
    "\n",
    "# Add 1 to start indexing at 1 to be conform with LSWR labels\n",
    "df.index += 1\n",
    "\n",
    "code = df.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "    label=\"errors-per-lswr-per-method\",\n",
    "    caption=f\"Normalized MAE and RMSE of the Default model for the resulting LSWRs.\",\n",
    ")\n",
    "\n",
    "\n",
    "with open(\n",
    "    \"/p/home/jusers/emmerich1/juwels/code/a6/notebooks/errors-table.tex\", \"w\"\n",
    ") as f:\n",
    "    f.write(code)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f6911-4f41-40e7-824d-0d8b1e17a9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_errors_per_method(\n",
    "    errors: dict[str, dict[int, ErrorsPerLswr]],\n",
    ") -> tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"Plot the mean and std of NMAE and NRMSE for each LSWR and method.\"\"\"\n",
    "    n_rows = len(errors)\n",
    "    n_cols = 2  # 1 column for NMAE and 1 for NRMSE\n",
    "    labels = np.arange(1, n_lswr_categories + 1, dtype=int)\n",
    "\n",
    "    x_lims = labels.min() - 0.5, labels.max() + 0.5\n",
    "    colors = _colors.create_colors_for_labels(labels)\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        figsize=(6 * n_cols, 2 * n_rows),\n",
    "        nrows=n_rows,\n",
    "        ncols=n_cols,\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Errors per LSWRs\")\n",
    "\n",
    "    for i, (method, errors_per_lswr) in enumerate(errors.items()):\n",
    "        for j, metric in enumerate((\"nrmse\", \"nmae\")):\n",
    "            error_means = [\n",
    "                np.nanmean(getattr(error, metric)) * 100\n",
    "                for error in errors_per_lswr.values()\n",
    "            ]\n",
    "            error_stds = [\n",
    "                np.nanstd(getattr(error, metric)) * 100\n",
    "                for error in errors_per_lswr.values()\n",
    "            ]\n",
    "            ax = axs[i][j]\n",
    "\n",
    "            ax.bar(\n",
    "                labels,\n",
    "                error_means,\n",
    "                yerr=error_stds,\n",
    "                width=1.0,  # removes gaps between the bars\n",
    "                color=colors,\n",
    "                align=\"center\",\n",
    "                alpha=1,\n",
    "                ecolor=\"black\",\n",
    "                capsize=3,\n",
    "            )\n",
    "\n",
    "            ax.set_title(method)\n",
    "\n",
    "            if i == n_rows - 1:\n",
    "                ax.set_xlabel(\"LSWR\")\n",
    "\n",
    "            ax.set_ylabel(f\"{metric.upper()} [%]\")\n",
    "            ax.set_xlim(*x_lims)\n",
    "            ax.set_xticks(labels)\n",
    "            ax.set_xticklabels(labels, rotation=90)\n",
    "            ax.yaxis.grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(plots / \"lswrs-errors-comparison.pdf\")\n",
    "\n",
    "\n",
    "plot_errors_per_method(errors_per_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1db8dc-c6fd-4701-b254-5993ece5f15e",
   "metadata": {},
   "source": [
    "## Create timeseries plot with NRMSE for every LSWR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2993a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataclasses\n",
    "import datetime\n",
    "\n",
    "start, end = min(min(turbine.time.values) for turbine in turbine_errors), max(\n",
    "    max(turbine.time.values) for turbine in turbine_errors\n",
    ")\n",
    "date_range = pd.date_range(start, end, freq=\"1d\")\n",
    "date_range\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ErrorsPerDay:\n",
    "    time: pd.Timestamp\n",
    "    measurements: int = 0\n",
    "    nmae: list[int] = dataclasses.field(default_factory=list)\n",
    "    nrmse: list[int] = dataclasses.field(default_factory=list)\n",
    "\n",
    "\n",
    "def get_errors_per_day(\n",
    "    data: xr.DataArray | None,\n",
    ") -> dict[pd.Timestamp, ErrorsPerDay]:\n",
    "    name = data.name if isinstance(data, xr.DataArray) else data\n",
    "    errors_per_day = {step: ErrorsPerDay(time=step) for step in date_range}\n",
    "\n",
    "    for i, step in enumerate(date_range):\n",
    "        day_errors = errors_per_day[step]\n",
    "\n",
    "        for j, turbine in enumerate(turbine_errors):\n",
    "            print(\n",
    "                f\"{name}: day {i}/{len(date_range)}, turbine {j}/{len(turbine_errors)}\",\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "\n",
    "            if step not in turbine[\"time\"]:\n",
    "                continue\n",
    "\n",
    "            turbine_sub = turbine.sel(time=step, lswr_method=name)\n",
    "\n",
    "            # Add to counter for turbines that contribute to the results\n",
    "            day_errors.measurements += 1\n",
    "\n",
    "            # Select time steps of LSWR appearance and calculate mean\n",
    "            nmae = turbine_sub[\"nmae\"]\n",
    "            day_errors.nmae.append(nmae.values.tolist())\n",
    "\n",
    "            nrmse = turbine_sub[\"nrmse\"]\n",
    "            day_errors.nrmse.append(nrmse.values.tolist())\n",
    "\n",
    "    return errors_per_day\n",
    "\n",
    "\n",
    "errors_per_day = {\n",
    "    (lswr.name if isinstance(lswr, xr.DataArray) else lswr): get_errors_per_day(\n",
    "        lswr\n",
    "    )\n",
    "    for lswr in lswrs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db165a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_rows = len(lswrs)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    figsize=(12, 4 * n_rows), nrows=n_rows, ncols=1, sharex=True\n",
    ")\n",
    "\n",
    "means_per_day = []\n",
    "stds_per_day = []\n",
    "\n",
    "attr = \"nmae\"\n",
    "\n",
    "for results in errors_per_day.values():\n",
    "    mean_per_day = (\n",
    "        np.array([np.nanmean(getattr(day, attr)) for day in results.values()])\n",
    "        * 100\n",
    "    )\n",
    "    std_per_day = (\n",
    "        np.array([np.nanstd(getattr(day, attr)) for day in results.values()])\n",
    "        * 100\n",
    "    )\n",
    "\n",
    "    means_per_day.append(mean_per_day)\n",
    "    stds_per_day.append(std_per_day)\n",
    "\n",
    "x_start, x_end = 100, 300\n",
    "\n",
    "global_max = np.nanmax(\n",
    "    [\n",
    "        np.nanmax(m[x_start:x_end] + s[x_start:x_end])\n",
    "        for m, s in zip(means_per_day, stds_per_day)\n",
    "    ]\n",
    ")\n",
    "global_min = np.nanmin(\n",
    "    [\n",
    "        np.nanmin(m[x_start:x_end] - s[x_start:x_end])\n",
    "        for m, s in zip(means_per_day, stds_per_day)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# If global minimum is lower than 2%, set it to 0.\n",
    "# This is used for the ylim in each plot\n",
    "if global_min < 2.0:\n",
    "    global_min = 0.0\n",
    "\n",
    "x = list(range(len(date_range)))\n",
    "\n",
    "for i, (name, results) in enumerate(errors_per_day.items()):\n",
    "    ax = axs[i]\n",
    "\n",
    "    mean_per_day = means_per_day[i]\n",
    "    std_per_day = stds_per_day[i]\n",
    "\n",
    "    all_errs = (\n",
    "        np.array(\n",
    "            [nrmse for day in results.values() for nrmse in getattr(day, attr)]\n",
    "        )\n",
    "        * 100\n",
    "    )\n",
    "    global_mean = np.nanmean(all_errs)\n",
    "    global_std = np.nanstd(all_errs)\n",
    "\n",
    "    ax.plot(\n",
    "        x,\n",
    "        mean_per_day,\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        mean_per_day - std_per_day,\n",
    "        mean_per_day + std_per_day,\n",
    "        color=\"gray\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    # Plot global mean and standard deviation\n",
    "    ax.hlines(\n",
    "        y=global_mean,\n",
    "        xmin=-10,\n",
    "        xmax=x[-1] + 10,\n",
    "        linewidth=1,\n",
    "        linestyle=\"--\",\n",
    "        color=\"black\",\n",
    "        label=rf\"$\\mu_\\mathrm{{{attr.upper()}}}^\\mathrm{{global}} = ({global_mean:.2f} \\pm {global_std:.2f})\\,\\%$\",\n",
    "    )\n",
    "\n",
    "    ax.hlines(\n",
    "        y=global_mean + global_std,\n",
    "        xmin=-10,\n",
    "        xmax=x[-1] + 10,\n",
    "        linewidth=1,\n",
    "        linestyle=\":\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "    ax.hlines(\n",
    "        y=global_mean - global_std,\n",
    "        xmin=-10,\n",
    "        xmax=x[-1] + 10,\n",
    "        linewidth=1,\n",
    "        linestyle=\":\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(name)\n",
    "\n",
    "    ax.set_xlim(x_start, x_end)\n",
    "\n",
    "    if i == n_rows - 1:\n",
    "        ax.set_xlabel(\"time\")\n",
    "        xticks = ax.get_xticks()\n",
    "        xticklabels = [\n",
    "            date_range[int(tick)].strftime(\"%Y-%m-%d\") for tick in xticks[1:]\n",
    "        ]\n",
    "        ax.set_xticklabels(xticklabels, rotation=45)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    ax.set_ylabel(rf\"$\\mu_\\mathrm{{{attr.upper()}}}$ [%]\")\n",
    "\n",
    "    ax.set_ylim(global_min * 0.9, global_max * 1.05)\n",
    "    ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(plots / f\"forecast-error-timeseries-per-lswr-method-{attr}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7c01d-4500-428b-a6f3-f46989167635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a6-cuda",
   "language": "python",
   "name": "a6-cuda"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
