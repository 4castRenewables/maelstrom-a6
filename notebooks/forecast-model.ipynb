{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb0cb71-eb0b-44ab-8a82-e4442f397eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import dataclasses\n",
    "import datetime\n",
    "import itertools\n",
    "import logging\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import xarray as xr\n",
    "import torch\n",
    "\n",
    "import a6\n",
    "import a6.datasets.coordinates as _coordinates\n",
    "import a6.datasets.variables as _variables\n",
    "import a6.utils as utils\n",
    "\n",
    "WORKER_ID = 10\n",
    "\n",
    "utils.logging.create_logger(\n",
    "    global_rank=WORKER_ID,\n",
    "    local_rank=WORKER_ID,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"notebook\")\n",
    "\n",
    "turbine_data_dir = pathlib.Path(\n",
    "    \"/p/home/jusers/emmerich1/juwels/data/production\"\n",
    ")\n",
    "preprocessed_data_dir = pathlib.Path(\n",
    "    \"/p/home/jusers/emmerich1/juwels/data/production-processed\"\n",
    ")\n",
    "results_dir = pathlib.Path(\n",
    "    \"/p/project/deepacf/maelstrom/emmerich1/data/forecast-errors\"\n",
    ")\n",
    "\n",
    "turbine_files = a6.utils.paths.list_files(\n",
    "    turbine_data_dir, pattern=\"**/*.nc\", recursive=True\n",
    ")\n",
    "\n",
    "results = xr.open_dataset(\"/p/project/deepacf/maelstrom/emmerich1/data/pca_kpca_kmeans_lswrs_29_40.nc\")\n",
    "results_40 = results.sel(k=40)\n",
    "gwl = xr.open_dataset(\"/p/home/jusers/emmerich1/juwels/code/a6/src/tests/data/gwl.nc\")\n",
    "dcv2 = xr.open_dataset(\"/p/project/deepacf/maelstrom/emmerich1/data/dcv2-lswrs.nc\")\n",
    "\n",
    "lswrs = [None, gwl[\"GWL\"], results_40[\"PCA\"], results_40[\"kPCA\"], dcv2[\"DCv2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72189815-3a31-4aeb-b742-11fdb4fdfc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Errors:\n",
    "    nmae: float\n",
    "    nrmse: float\n",
    "\n",
    "\n",
    "def _calculate_nmae_and_nrmse(\n",
    "    start: datetime.datetime,\n",
    "    end: datetime.datetime,\n",
    "    gs: sklearn.model_selection.GridSearchCV,\n",
    "    weather_data: list[xr.DataArray],\n",
    "    turbine: xr.Dataset,\n",
    "    power_rating: float,\n",
    "    turbine_variables: _variables.Turbine,\n",
    "    coordinates: _coordinates.Coordinates,\n",
    ") -> Errors:\n",
    "    window = slice(start, end)\n",
    "    logger.debug(\"Evaluating model error for slice=%s\", window)\n",
    "\n",
    "    weather_forecast = [d.sel({coordinates.time: window}) for d in weather_data]\n",
    "    X_forecast = a6.features.methods.reshape.sklearn.transpose(  # noqa: N806\n",
    "        *weather_forecast\n",
    "    )\n",
    "\n",
    "    turbine_sub = turbine.sel({coordinates.time: window})[\n",
    "        turbine_variables.production\n",
    "    ]\n",
    "    y_true = a6.features.methods.reshape.sklearn.transpose(turbine_sub)\n",
    "\n",
    "    if y_true.size == 0:\n",
    "        logger.warning(\n",
    "            (\n",
    "                \"Emtpy production data for start=%s \"\n",
    "                \"end=%s, setting errors to NaN\"\n",
    "            ),\n",
    "            start,\n",
    "            end,\n",
    "        )\n",
    "        return Errors(np.nan, np.nan)\n",
    "\n",
    "    y_pred = gs.predict(X_forecast)\n",
    "\n",
    "    nmae = a6.training.metrics.turbine.calculate_nmae(\n",
    "        y_true=y_true, y_pred=y_pred, power_rating=power_rating\n",
    "    )\n",
    "    nrmse = a6.training.metrics.turbine.calculate_nrmse(\n",
    "        y_true=y_true, y_pred=y_pred, power_rating=power_rating\n",
    "    )\n",
    "    return Errors(nmae=nmae, nrmse=nrmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f724f5b-e959-480b-acb4-dcd8895a54ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:13:42 - 0:00:34 - Processing turbine 10/45 (path=/p/home/jusers/emmerich1/juwels/data/production/hohw1.nc)\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:13:42 - 0:00:34 - Reading preprocessed data\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:13:42 - 0:00:34 - Extracted power rating 2000\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:13:42 - 0:00:35 - Simulating forecast errors for LSWRS [None, <xarray.DataArray 'GWL' (time: 15777)>\n",
      "                                                            [15777 values with dtype=int64]\n",
      "                                                            Coordinates:\n",
      "                                                              * time     (time) datetime64[ns] 1979-07-01 1979-07-02 ... 2022-10-13, <xarray.DataArray 'PCA' (time: 21826)>\n",
      "                                                            [21826 values with dtype=int32]\n",
      "                                                            Coordinates:\n",
      "                                                              * time     (time) datetime64[ns] 1964-01-01 1964-01-02 ... 2023-10-03\n",
      "                                                                k        int64 40, <xarray.DataArray 'kPCA' (time: 21826)>\n",
      "                                                            [21826 values with dtype=int32]\n",
      "                                                            Coordinates:\n",
      "                                                              * time     (time) datetime64[ns] 1964-01-01 1964-01-02 ... 2023-10-03\n",
      "                                                                k        int64 40, <xarray.DataArray 'DCv2' (time: 21826)>\n",
      "                                                            [21826 values with dtype=int64]\n",
      "                                                            Coordinates:\n",
      "                                                              * time     (time) datetime64[ns] 1964-01-01 1964-01-02 ... 2023-10-03] for date range 2017-01-01T00:00:00.000000000-2020-12-31T23:00:00.000000000\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:13:42 - 0:00:35 - Preparing input data for variables ['t', 'sp', 'spd', 'dir', 'r', 'fraction_of_year', 'fraction_of_day']\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:15:11 - 0:02:03 - Train dataset size is 10079 hours (~419 days)\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:15:11 - 0:02:03 - Fitting model with GridSearchCV\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:15:21 - 0:02:13 - Evaluating model error for slice=slice(Timestamp('2017-01-01 00:00:00'), Timestamp('2017-01-02 00:00:00'), None)\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:15:21 - 0:02:13 - Evaluating model error for slice=slice(Timestamp('2017-01-02 00:00:00'), Timestamp('2017-01-03 00:00:00'), None)\n",
      "RANK 10 (LOCAL 10) - WARNING - 2024-03-28 18:15:21 - 0:02:14 - Skipping /p/home/jusers/emmerich1/juwels/data/production-processed/hohw1/turbine.nc since outfile already exists at /p/project/deepacf/maelstrom/emmerich1/data/forecast-errors/hohw1-forecast-errors-lswr-GWL.nc\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:15:21 - 0:02:14 - Preparing input data for variables ['t', 'sp', 'spd', 'dir', 'r', 'fraction_of_year', 'fraction_of_day', 'GWL']\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:16:58 - 0:03:51 - Train dataset size is 10079 hours (~419 days)\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:16:58 - 0:03:51 - Fitting model with GridSearchCV\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:17:05 - 0:03:58 - Evaluating model error for slice=slice(Timestamp('2017-01-01 00:00:00'), Timestamp('2017-01-02 00:00:00'), None)\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:17:06 - 0:03:58 - Evaluating model error for slice=slice(Timestamp('2017-01-02 00:00:00'), Timestamp('2017-01-03 00:00:00'), None)\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:17:06 - 0:03:58 - Preparing input data for variables ['t', 'sp', 'spd', 'dir', 'r', 'fraction_of_year', 'fraction_of_day', 'PCA']\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:18:44 - 0:05:36 - Train dataset size is 10079 hours (~419 days)\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:18:44 - 0:05:36 - Fitting model with GridSearchCV\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:18:51 - 0:05:43 - Evaluating model error for slice=slice(Timestamp('2017-01-01 00:00:00'), Timestamp('2017-01-02 00:00:00'), None)\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:18:51 - 0:05:43 - Evaluating model error for slice=slice(Timestamp('2017-01-02 00:00:00'), Timestamp('2017-01-03 00:00:00'), None)\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:18:51 - 0:05:44 - Preparing input data for variables ['t', 'sp', 'spd', 'dir', 'r', 'fraction_of_year', 'fraction_of_day', 'kPCA']\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:20:30 - 0:07:22 - Train dataset size is 10079 hours (~419 days)\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:20:30 - 0:07:22 - Fitting model with GridSearchCV\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:20:37 - 0:07:30 - Evaluating model error for slice=slice(Timestamp('2017-01-01 00:00:00'), Timestamp('2017-01-02 00:00:00'), None)\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:20:37 - 0:07:30 - Evaluating model error for slice=slice(Timestamp('2017-01-02 00:00:00'), Timestamp('2017-01-03 00:00:00'), None)\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:20:39 - 0:07:32 - Preparing input data for variables ['t', 'sp', 'spd', 'dir', 'r', 'fraction_of_year', 'fraction_of_day', 'DCv2']\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:22:17 - 0:09:09 - Train dataset size is 10079 hours (~419 days)\n",
      "RANK 10 (LOCAL 10) - INFO - 2024-03-28 18:22:17 - 0:09:09 - Fitting model with GridSearchCV\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:22:20 - 0:09:12 - Evaluating model error for slice=slice(Timestamp('2017-01-01 00:00:00'), Timestamp('2017-01-02 00:00:00'), None)\n",
      "RANK 10 (LOCAL 10) - DEBUG - 2024-03-28 18:22:20 - 0:09:13 - Evaluating model error for slice=slice(Timestamp('2017-01-02 00:00:00'), Timestamp('2017-01-03 00:00:00'), None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if WORKER_ID is not None and WORKER_ID >= len(turbine_files):\n",
    "    logger.warning(\"Exiting: no file to process\")\n",
    "    raise RuntimeError()\n",
    "\n",
    "coordinates: _coordinates.Coordinates = _coordinates.Coordinates()\n",
    "turbine_variables: _variables.Turbine = a6.datasets.variables.Turbine()\n",
    "\n",
    "result = {}\n",
    "\n",
    "for i, turbine_path in enumerate(turbine_files):\n",
    "    if WORKER_ID is not None and i != WORKER_ID:\n",
    "        continue\n",
    "\n",
    "    logger.info(\n",
    "        \"Processing turbine %i/%i (path=%s)\",\n",
    "        i,\n",
    "        len(turbine_files),\n",
    "        turbine_path,\n",
    "    )\n",
    "\n",
    "    turbine_name = turbine_path.name.replace(\".nc\", \"\")\n",
    "\n",
    "    turbine_path: pathlib.Path = (\n",
    "        preprocessed_data_dir / f\"{turbine_name}/turbine.nc\"\n",
    "    )\n",
    "    pl_path: pathlib.Path = (\n",
    "        preprocessed_data_dir / f\"{turbine_name}/pl.nc\"\n",
    "    )\n",
    "    ml_path: pathlib.Path = (\n",
    "        preprocessed_data_dir / f\"{turbine_name}/ml.nc\"\n",
    "    )\n",
    "    sfc_path: pathlib.Path = (\n",
    "        preprocessed_data_dir / f\"{turbine_name}/sfc.nc\"\n",
    "    )\n",
    "\n",
    "    logger.info(\"Reading preprocessed data\")\n",
    "    turbine = xr.open_dataset(turbine_path)\n",
    "    pl = xr.open_dataset(pl_path)\n",
    "    ml = xr.open_dataset(ml_path)\n",
    "    sfc = xr.open_dataset(sfc_path)\n",
    "\n",
    "    power_rating = turbine_variables.read_power_rating(turbine)\n",
    "    logger.info(\"Extracted power rating %i\", power_rating)\n",
    "    \n",
    "    start, end = min(turbine[\"time\"].values), max(turbine[\"time\"].values)\n",
    "    dates = pd.date_range(start, end, freq=\"1d\")\n",
    "    logger.info(\n",
    "        \"Simulating forecast errors for LSWRS %s for date range %s-%s\",\n",
    "        lswrs,\n",
    "        start,\n",
    "        end,\n",
    "    )\n",
    "\n",
    "    forecast_errors = {}\n",
    "    \n",
    "    for lswr in lswrs:\n",
    "        lswr_name = \"none\" if lswr is None else lswr.name\n",
    "        \n",
    "        logger.info(\"Handling LSWR %s\", lswr_name)\n",
    "        \n",
    "        outfile: pathlib.Path = (\n",
    "            results_dir / f\"{turbine_name}-forecast-errors-lswr-{lswr_name}.nc\"\n",
    "        )\n",
    "\n",
    "        if outfile.exists():\n",
    "            logger.warning(\n",
    "                \"Skipping %s since outfile already exists at %s\",\n",
    "                turbine_path,\n",
    "                outfile,\n",
    "            )\n",
    "            \n",
    "        data = [ml[var] for var in ml.data_vars] + [sfc[var] for var in sfc.data_vars] + [pl[var] for var in pl.data_vars]\n",
    "        categorical_features = [False for _ in enumerate(data)]\n",
    "        \n",
    "        if lswr is not None:\n",
    "            lswr_labels = lswr.sel(time=turbine[coordinates.time], method=\"nearest\")\n",
    "            data.append(lswr_labels)\n",
    "            categorical_features.append(True)\n",
    "        \n",
    "        logger.info(\n",
    "            \"Preparing input data for variables %s\", [d.name for d in data]\n",
    "        )\n",
    "\n",
    "        X = a6.features.methods.reshape.sklearn.transpose(*data)  # noqa: N806\n",
    "        y = a6.features.methods.reshape.sklearn.transpose(\n",
    "            turbine[turbine_variables.production]\n",
    "        )\n",
    "\n",
    "        (  # noqa: N806\n",
    "            X_train,\n",
    "            _,\n",
    "            y_train,\n",
    "            _,\n",
    "        ) = sklearn.model_selection.train_test_split(X, y, train_size=1/3)\n",
    "\n",
    "        logger.info(\n",
    "            \"Train dataset size is %i hours (~%i days)\",\n",
    "            y_train.size,\n",
    "            y_train.size // 24,\n",
    "        )\n",
    "\n",
    "        logger.info(\"Fitting model with GridSearchCV\")\n",
    "\n",
    "\n",
    "        param_grid = {\n",
    "            \"learning_rate\": [0.03, 0.05, 0.07, 0.1],\n",
    "            \"l2_regularization\": [0.0, 1.0, 3.0, 5.0, 7.0],\n",
    "            \"max_iter\": [200, 300, 500],\n",
    "            \"max_depth\": [15, 37, 63, 81],\n",
    "            \"min_samples_leaf\": [23, 48, 101, 199],\n",
    "            \"categorical_features\": [categorical_features],\n",
    "        }\n",
    "        param_grid = {\"learning_rate\": [0.1]}\n",
    "        n_jobs = int(a6.utils.get_cpu_count())\n",
    "\n",
    "        gs = sklearn.model_selection.GridSearchCV(\n",
    "            estimator=ensemble.HistGradientBoostingRegressor(\n",
    "                loss=\"squared_error\"\n",
    "            ),\n",
    "            param_grid=param_grid,\n",
    "            scoring=sklearn.metrics.make_scorer(\n",
    "                a6.training.metrics.turbine.calculate_nrmse,\n",
    "                greater_is_better=False,\n",
    "                power_rating=power_rating,\n",
    "            ),\n",
    "            # 10-fold CV\n",
    "            cv=2,\n",
    "            refit=True,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "        gs = gs.fit(X=X_train, y=y_train.ravel())\n",
    "\n",
    "        results: list[Errors] = [\n",
    "            _calculate_nmae_and_nrmse(\n",
    "                start=start,\n",
    "                end=end,\n",
    "                gs=gs,\n",
    "                weather_data=data,\n",
    "                turbine=turbine,\n",
    "                power_rating=power_rating,\n",
    "                turbine_variables=turbine_variables,\n",
    "                coordinates=coordinates,\n",
    "            )\n",
    "            for start, end in itertools.pairwise(dates[:3])\n",
    "        ]\n",
    "        forecast_errors[lswr_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24a3d270-8f85-4ba4-b3c6-6054ee52e368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unpack_errors_per_method(errors, attr: str):\n",
    "    return [\n",
    "        [getattr(error, attr) for error in method]\n",
    "        for method in zip(*errors.values())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20c7db5a-33a8-42d6-9916-1515e07ce31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"time\": dates[:2], \"lswr_method\": list(forecast_errors.keys())}\n",
    "dims = [\"time\", \"lswr_method\"]\n",
    "                                     \n",
    "nmae_da = xr.DataArray(\n",
    "    unpack_errors_per_method(forecast_errors, attr=\"nmae\"),\n",
    "    coords=coords,\n",
    "    dims=dims,\n",
    ")\n",
    "nrmse_da = xr.DataArray(\n",
    "    unpack_errors_per_method(forecast_errors, attr=\"nrmse\"),\n",
    "    coords=coords,\n",
    "    dims=dims,\n",
    ")\n",
    "errors = xr.Dataset(\n",
    "    data_vars={\"nmae\": nmae_da, \"nrmse\": nrmse_da},\n",
    "    coords=nmae_da.coords,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a6-cuda",
   "language": "python",
   "name": "a6-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
