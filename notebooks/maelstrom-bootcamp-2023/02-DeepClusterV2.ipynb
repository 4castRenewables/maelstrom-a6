{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec5ac82-15e4-4d80-98bb-afc673f9c19b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.constants as constants\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xarray as xr\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import a6\n",
    "import a6.dcv2._logs as logs\n",
    "import a6.dcv2._averaging as averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63874afa-4a9d-4985-a73e-783ffe6dc4d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming dataset from netCDF files\n",
      "Reading data from netCDF files [PosixPath('/p/project/training2330/a6/data/ecmwf_era5/nc/era5_pl_2012_2023_12.nc')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.11/site-packages/gribapi/__init__.py:23: UserWarning: ecCodes 2.31.0 or higher is recommended. You are running version 2.30.0\n",
      "  warnings.warn(\n",
      "Converted relative crop sizes (0.75,) to specific crop sizes [105]\n"
     ]
    }
   ],
   "source": [
    "@a6.utils.make_functional\n",
    "def calculate_geopotential_height(\n",
    "    data: xr.Dataset,\n",
    "    scaling: float = 10.0,\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Calculate the geopotential height from the geopotential.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    data : xr.Dataset\n",
    "        Data containing the geopotential.\n",
    "    scaling : float, default=10.0\n",
    "        Parameter used for scaling the data.\n",
    "        E.g. the ERA5 geopotential is given in decameters.\n",
    "\n",
    "    \"\"\"\n",
    "    data[\"z_h\"] = data[\"z\"] / constants.g / scaling\n",
    "    return data\n",
    "\n",
    "\n",
    "@a6.utils.make_functional\n",
    "def drop_variables_from_dataset(\n",
    "    data: xr.Dataset,\n",
    "    names: str | list[str],\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Drop variables from dataset.\"\"\"\n",
    "    return data.drop_vars(names)\n",
    "\n",
    "\n",
    "def create_dataset(\n",
    "    paths: pathlib.Path | list[pathlib.Path],\n",
    "    is_netcdf: bool,\n",
    "    nmb_crops: tuple[int, ...],\n",
    "    size_crops: tuple[float, ...],\n",
    "    min_scale_crops: tuple[float, ...],\n",
    "    max_scale_crops: tuple[float, ...],\n",
    "    drop_variables: list[str] | None = None,\n",
    ") -> a6.datasets.crop.Base:\n",
    "    if is_netcdf:\n",
    "        print(\"Assuming dataset from netCDF files\")\n",
    "        drop_variables = drop_variables or []\n",
    "\n",
    "        preprocessing = (\n",
    "            a6.features.methods.weighting.weight_by_latitudes(\n",
    "                latitudes=\"latitude\",\n",
    "                use_sqrt=True,\n",
    "            )\n",
    "            >> calculate_geopotential_height()\n",
    "            >> drop_variables_from_dataset(names=[\"z\"])\n",
    "        )\n",
    "        print(f\"Reading data from netCDF files {paths}\")\n",
    "        ds = xr.open_mfdataset(\n",
    "            paths,\n",
    "            engine=\"netcdf4\",\n",
    "            concat_dim=\"time\",\n",
    "            combine=\"nested\",\n",
    "            coords=\"minimal\",\n",
    "            data_vars=\"minimal\",\n",
    "            preprocess=preprocessing,\n",
    "            drop_variables=drop_variables,\n",
    "            compat=\"override\",\n",
    "            parallel=False,\n",
    "        )\n",
    "\n",
    "        return a6.datasets.crop.MultiCropXarrayDataset(\n",
    "            data_path=path,\n",
    "            dataset=ds,\n",
    "            nmb_crops=nmb_crops,\n",
    "            size_crops=size_crops,\n",
    "            min_scale_crops=min_scale_crops,\n",
    "            max_scale_crops=max_scale_crops,\n",
    "            return_index=True,\n",
    "        )\n",
    "    print(\"Assuming image folder dataset\")\n",
    "    return a6.datasets.crop.MultiCropDataset(\n",
    "        data_path=path,\n",
    "        nmb_crops=nmb_crops,\n",
    "        size_crops=size_crops,\n",
    "        min_scale_crops=min_scale_crops,\n",
    "        max_scale_crops=max_scale_crops,\n",
    "        return_index=True,\n",
    "    )\n",
    "\n",
    "\n",
    "path = pathlib.Path(\n",
    "    \"/p/project/training2330/a6/data/ecmwf_era5/nc/era5_pl_2012_2023_12.nc\"\n",
    ")\n",
    "nmb_crops = (2,)\n",
    "crops_for_assign = (0, 1)\n",
    "size_crops = (0.75,)\n",
    "min_scale_crops = (0.15,)\n",
    "max_scale_crops = (1.0,)\n",
    "\n",
    "train_dataset = create_dataset(\n",
    "    paths=[path],\n",
    "    is_netcdf=True,\n",
    "    nmb_crops=nmb_crops,\n",
    "    size_crops=size_crops,\n",
    "    min_scale_crops=min_scale_crops,\n",
    "    max_scale_crops=max_scale_crops,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1ed04-1b4b-444c-8344-957a9f7be68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = a6.datasets.Era5(\n",
    "    path=pathlib.Path(\"/p/project/training2330/a6/data/ecmwf_era5/nc\"),\n",
    "    pattern=\"*.nc\",\n",
    ")\n",
    "ds = data.to_xarray()\n",
    "ds.to_netcdf(\"/p/project/training2330/a6/data/ecmwf_era5/era5_pl_1964_2023.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c47d33-7d0f-4290-ad46-5089141421f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_memory(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: nn.Module,\n",
    "    device: torch.device,\n",
    "    feature_dimensions: int,\n",
    "    crops_for_assign: tuple[int, float],\n",
    "    drop_last: bool = False,\n",
    "):\n",
    "    size_dataset = len(dataloader.dataset)\n",
    "    print(\"Dataset size is %s samples\", size_dataset)\n",
    "\n",
    "    if drop_last:\n",
    "        size_dataset -= size_dataset % settings.model.batch_size\n",
    "        print(\n",
    "            \"Adjusted size of memory per process due to drop_last=True to %s\",\n",
    "            size_dataset,\n",
    "        )\n",
    "\n",
    "    print(\"Processing %s samples\", size_dataset)\n",
    "\n",
    "    indexes = torch.zeros(size_dataset).long().to(device=device)\n",
    "    embeddings = torch.zeros(\n",
    "        len(crops_for_assign),\n",
    "        size_dataset,\n",
    "        feature_dimensions,\n",
    "    ).to(device=device)\n",
    "\n",
    "    start_idx = 0\n",
    "    with torch.no_grad():\n",
    "        print(\"Start initializing the memory banks\")\n",
    "        for index, inputs in dataloader:\n",
    "            n_indexes = inputs[0].size(0)\n",
    "            index = index.to(device=device, non_blocking=True)\n",
    "\n",
    "            # get embeddings\n",
    "            outputs = []\n",
    "            for crop_idx in crops_for_assign:\n",
    "                inp = inputs[crop_idx].to(device=device, non_blocking=True)\n",
    "                outputs.append(model(inp)[0])\n",
    "\n",
    "            # fill the memory bank\n",
    "            indexes[start_idx : start_idx + n_indexes] = index\n",
    "            for mb_idx, output in enumerate(outputs):\n",
    "                embeddings[mb_idx] = output\n",
    "            start_idx += n_indexes\n",
    "    print(\n",
    "        \"Initialization of the memory banks done with %s local memory indexes\",\n",
    "        indexes.size(),\n",
    "    )\n",
    "    return indexes, embeddings\n",
    "\n",
    "\n",
    "def cluster_memory(\n",
    "    epoch: int,\n",
    "    model,\n",
    "    indexes: torch.Tensor,\n",
    "    embeddings: torch.Tensor,\n",
    "    size_dataset: int,\n",
    "    device: torch.device,\n",
    "    crops_for_assign: tuple[float, ...],\n",
    "    nmb_prototypes: tuple[int, ...],\n",
    "    feature_dimensions: int,\n",
    "    n_epochs: int,\n",
    "    nmb_kmeans_iters: int,\n",
    "    plots_path: pathlib.Path = pathlib.Path(\".\"),\n",
    "):\n",
    "    print(f\"Clustering {size_dataset} samples\")\n",
    "\n",
    "    # j defines which crops are used for the K-means run.\n",
    "    # E.g. if the number of crops (``self.nmb_mbs``) is 2, and\n",
    "    # ``self.num_clusters = [30, 30, 30, 30]``, the crops will\n",
    "    # be used as following:\n",
    "    #\n",
    "    # 1. K=30, j=0\n",
    "    # 2. K=30, j=1\n",
    "    # 3. K=30, j=0\n",
    "    # 4. K=30, j=1\n",
    "    j = 0\n",
    "\n",
    "    n_heads = len(nmb_prototypes)\n",
    "\n",
    "    assignments_per_prototype = (torch.zeros(n_heads, size_dataset).long()).to(\n",
    "        device\n",
    "    )\n",
    "    indexes_per_prototype = torch.zeros(n_heads, size_dataset).long().to(device)\n",
    "\n",
    "    embeddings_per_prototype = torch.zeros(\n",
    "        n_heads,\n",
    "        *tuple(embeddings.size()),\n",
    "    ).to(device)\n",
    "    distances_per_prototype = torch.zeros(n_heads, size_dataset).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i_K, K in enumerate(nmb_prototypes):\n",
    "            # run k-means\n",
    "\n",
    "            # init with random samples as centroids from the dataset\n",
    "            centroids = torch.empty(K, feature_dimensions).to(\n",
    "                device=device, non_blocking=True\n",
    "            )\n",
    "\n",
    "            batch_size = len(embeddings[j])\n",
    "            random_idx = torch.randperm(batch_size)[:K]\n",
    "            assert len(random_idx) >= K, (\n",
    "                f\"Please reduce the number of centroids K={K}: \"\n",
    "                f\"K must be smaller than batch size {batch_size}\"\n",
    "            )\n",
    "            centroids = embeddings[j][random_idx]\n",
    "\n",
    "            for n_iter in range(nmb_kmeans_iters + 1):\n",
    "                # E step\n",
    "                dot_products = torch.mm(embeddings[j], centroids.t())\n",
    "                distances, assignments = dot_products.max(dim=1)\n",
    "\n",
    "                # finish\n",
    "                if n_iter == nmb_kmeans_iters:\n",
    "                    break\n",
    "\n",
    "                # M step\n",
    "                where_helper = _get_indices_sparse(assignments.cpu().numpy())\n",
    "                counts = (\n",
    "                    torch.zeros(K).to(device=device, non_blocking=True).int()\n",
    "                )\n",
    "                emb_sums = torch.zeros(K, feature_dimensions).to(\n",
    "                    device=device, non_blocking=True\n",
    "                )\n",
    "                for k in range(len(where_helper)):\n",
    "                    if len(where_helper[k][0]) > 0:\n",
    "                        emb_sums[k] = torch.sum(\n",
    "                            embeddings[j][where_helper[k][0]],\n",
    "                            dim=0,\n",
    "                        )\n",
    "                        counts[k] = len(where_helper[k][0])\n",
    "                mask = counts > 0\n",
    "                centroids[mask] = emb_sums[mask] / counts[mask].unsqueeze(1)\n",
    "\n",
    "                # normalize centroids\n",
    "                centroids = nn.functional.normalize(centroids, dim=1, p=2)\n",
    "\n",
    "            # Copy centroids to model for forwarding\n",
    "            getattr(\n",
    "                model.module.prototypes,\n",
    "                \"prototypes\" + str(i_K),\n",
    "            ).weight.copy_(centroids)\n",
    "\n",
    "            print(f\"embeddings[j]: {embeddings[j].size()}\")\n",
    "\n",
    "            # Save results to local tensors\n",
    "            assignments_per_prototype[i_K][indexes] = assignments\n",
    "            indexes_per_prototype[i_K][indexes] = indexes\n",
    "            distances_per_prototype[i_K][indexes] = distances\n",
    "            # For the embeddings, make sure to use j for indexing\n",
    "            embeddings_per_prototype[i_K][j][indexes] = embeddings\n",
    "\n",
    "            j_prev = j\n",
    "            # next memory bank to use\n",
    "            j = (j + 1) % len(crops_for_assign)\n",
    "\n",
    "        epoch_comp = epoch + 1\n",
    "\n",
    "        if (\n",
    "            # Plot for the first epoch\n",
    "            epoch_comp == 1\n",
    "            # Below 100 epochs, plot every 25 epochs,\n",
    "            or (epoch_comp <= 100 and epoch_comp % 25 == 0)\n",
    "            # Plot every hundredth epoch\n",
    "            or epoch_comp % 100 == 0\n",
    "            # Plot for the last epoch\n",
    "            or epoch_comp == n_epochs\n",
    "        ):\n",
    "\n",
    "            # Save which random samples were used as the centroids.\n",
    "            assignments_cpu = assignments[-1].cpu()\n",
    "            a6.plotting.embeddings.plot_embeddings_using_tsne(\n",
    "                embeddings=embeddings[-1],\n",
    "                # Use previous j since this represents which crops\n",
    "                # were used for last cluster iteration.\n",
    "                j=j_prev,\n",
    "                assignments=assignments_cpu,\n",
    "                centroids=random_idx,\n",
    "                name=f\"epoch-{epoch}-embeddings\",\n",
    "                output_dir=plots_path,\n",
    "            )\n",
    "            a6.plotting.assignments.plot_abundance(\n",
    "                assignments=assignments_cpu,\n",
    "                name=f\"epoch-{epoch}-assignments-abundance\",\n",
    "                output_dir=plots_path,\n",
    "            )\n",
    "            a6.plotting.transitions.plot_transition_matrix_heatmap(\n",
    "                assignments_cpu,\n",
    "                name=f\"epoch-{epoch}-transition-heatmap\",\n",
    "                output_dir=plots_path,\n",
    "            )\n",
    "            a6.plotting.transitions.plot_transition_matrix_clustermap(\n",
    "                assignments_cpu,\n",
    "                name=f\"epoch-{epoch}-transition-clustermap\",\n",
    "                output_dir=plots_path,\n",
    "            )\n",
    "\n",
    "    return assignments\n",
    "\n",
    "\n",
    "def _get_indices_sparse(data):\n",
    "    cols = np.arange(data.size)\n",
    "    M = csr_matrix(\n",
    "        (cols, (data.ravel(), cols)), shape=(int(data.max()) + 1, data.size)\n",
    "    )\n",
    "    return [np.unravel_index(row.data, data.shape) for row in M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537b8cd8-a1cf-4932-9f46-b98d86597d98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    indexes: torch.Tensor,\n",
    "    embeddings: torch.Tensor,\n",
    "    nmb_crops: tuple[float, ...],\n",
    "    crops_for_assign: tuple[float, ...],\n",
    "    nmb_prototypes: tuple[int, ...],\n",
    "    feature_dimensions: int,\n",
    "    n_epochs: int,\n",
    "    nmb_kmeans_iters: int,\n",
    "    temperature: float,\n",
    "    device: torch.device,\n",
    "):\n",
    "    batch_time = averaging.AverageMeter()\n",
    "    data_time = averaging.AverageMeter()\n",
    "    losses = averaging.AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    assignments = cluster_memory(\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        indexes=indexes,\n",
    "        embeddings=embeddings,\n",
    "        size_dataset=len(dataloader.dataset),\n",
    "        device=device,\n",
    "        crops_for_assign=crops_for_assign,\n",
    "        nmb_prototypes=nmb_prototypes,\n",
    "        feature_dimensions=feature_dimensions,\n",
    "        nmb_kmeans_iters=nmb_kmeans_iters,\n",
    "        n_epochs=n_epochs,\n",
    "    )\n",
    "\n",
    "    print(f\"Clustering for epoch {epoch} done\")\n",
    "\n",
    "    end = time.time()\n",
    "    start_idx = 0\n",
    "    for it, (idx, inputs) in enumerate(dataloader):\n",
    "        print(f\"Calculating loss for index {idx}\")\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # ============ multi-res forward passes ... ============\n",
    "        # Output here returns the output for each head (prototype)\n",
    "        # and hence has size ``len(settings.model.nmb_prototypes)``.\n",
    "        emb, output = model(inputs)\n",
    "        emb = emb.detach()\n",
    "        bs = inputs[0].size(0)\n",
    "\n",
    "        print(f\"Batch size is {bs}\")\n",
    "\n",
    "        # ============ deepcluster-v2 loss ... ============\n",
    "        loss = 0\n",
    "        for h in range(len(nmb_prototypes)):\n",
    "            scores = output[h] / temperature\n",
    "            targets = (\n",
    "                assignments[h][idx]\n",
    "                .repeat(sum(nmb_crops))\n",
    "                .to(device=device, non_blocking=True)\n",
    "            )\n",
    "            loss += cross_entropy(scores, targets)\n",
    "        loss /= len(nmb_prototypes)\n",
    "\n",
    "        # ============ backward and optim step ... ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ update memory banks ... ============\n",
    "        embeddings[start_idx : start_idx + bs] = idx\n",
    "        for i, crop_idx in enumerate(crops_for_assign):\n",
    "            embeddings[i][start_idx : start_idx + bs] = emb[  # noqa: E203\n",
    "                crop_idx * bs : (crop_idx + 1) * bs\n",
    "            ]\n",
    "        start_idx += bs\n",
    "\n",
    "        # ============ misc ... ============\n",
    "        losses.update(loss.item(), inputs[0].size(0))\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if it % 50 == 0:\n",
    "            print(\n",
    "                f\"[EPOCH {epoch}, ITERATION {it}] \"\n",
    "                f\"batch time: {batch_time.val} ({batch_time.avg}) \"\n",
    "                f\"data load time: {data_time.val} ({data_time.avg}) \"\n",
    "                f\"loss: {losses.val} ({losses.avg}) \"\n",
    "                f\"lr: {optimizer.state_dict()['param_groups'][0]['lr']}\"\n",
    "            )\n",
    "    print(\n",
    "        f\"========= Memory Summary at epoch {epoch} =======\\n\"\n",
    "        f\"{torch.cuda.memory_summary()}\\n\",\n",
    "    )\n",
    "\n",
    "    return (epoch, losses.avg), indexes, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352f711d-4344-4704-bdf4-89c979e6bdb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building data done with 4294 images loaded\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 91\u001b[0m\n\u001b[1;32m     77\u001b[0m         scores, indexes, embeddings \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     78\u001b[0m             dataloader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[1;32m     79\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m             temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m         training_stats\u001b[38;5;241m.\u001b[39mupdate(scores)\n\u001b[0;32m---> 91\u001b[0m \u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnmb_crops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnmb_crops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrops_for_assign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrops_for_assign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m, in \u001b[0;36mstart\u001b[0;34m(train_dataset, epochs, nmb_crops, crops_for_assign, model_architecture, batch_size, drop_last, hidden_mlp, feature_dimensions, nmb_kmeans_iters, nmb_prototypes, base_lr, weight_decay, temperature)\u001b[0m\n\u001b[1;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m a6\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mresnet\u001b[38;5;241m.\u001b[39mModels[model_architecture](\n\u001b[1;32m     34\u001b[0m     normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39mtrain_dataset\u001b[38;5;241m.\u001b[39mn_channels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Copy model to GPU\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding model done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.11/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "def start(\n",
    "    train_dataset: a6.datasets.crop.Base,\n",
    "    epochs: int,\n",
    "    nmb_crops: tuple[float, ...],\n",
    "    crops_for_assign: tuple[float, ...],\n",
    "    model_architecture: a6.models.resnet.Architecture = a6.models.resnet.Architecture.ResNet50,\n",
    "    batch_size: int = 64,\n",
    "    drop_last: bool = False,\n",
    "    hidden_mlp: int = 2048,\n",
    "    feature_dimensions: int = 128,\n",
    "    nmb_kmeans_iters: int = 10,\n",
    "    nmb_prototypes: list[int, ...] = [40, 40, 40],\n",
    "    base_lr: float = 4.8,\n",
    "    weight_decay: float = 1e-6,\n",
    "    temperature: float = 0.1,\n",
    "):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        # ``drop_last=True`` gives each device the same amount of samples,\n",
    "        # but removes some from the clustering.\n",
    "        drop_last=drop_last,\n",
    "        worker_init_fn=a6.utils.distributed.set_dataloader_seeds,\n",
    "    )\n",
    "    print(f\"Building data done with {len(train_dataset)} images loaded\")\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    # build model\n",
    "    model = a6.models.resnet.Models[model_architecture](\n",
    "        normalize=True,\n",
    "        in_channels=train_dataset.n_channels,\n",
    "        hidden_mlp=hidden_mlp,\n",
    "        output_dim=feature_dimensions,\n",
    "        nmb_prototypes=nmb_prototypes,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Copy model to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(model)\n",
    "    print(\"Building model done\")\n",
    "\n",
    "    # build optimizer\n",
    "    # Should be done after moving the model to GPU\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=base_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    print(\"Building optimizer done\")\n",
    "    training_stats = logs.Stats(\"stats.csv\", columns=(\"epoch\", \"loss\"))\n",
    "\n",
    "    indexes, embeddings = init_memory(\n",
    "        dataloader=train_loader,\n",
    "        model=model,\n",
    "        device=device,\n",
    "        feature_dimensions=feature_dimensions,\n",
    "        crops_for_assign=crops_for_assign,\n",
    "        drop_last=drop_last,\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # train the network for one epoch\n",
    "        print(f\"============ Starting epoch {epoch} ============\")\n",
    "\n",
    "        # set sampler\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        # train the network\n",
    "        scores, indexes, embeddings = train.train(\n",
    "            dataloader=train_loader,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch,\n",
    "            indexes=indexes,\n",
    "            embeddings=embeddings,\n",
    "            nmb_crops=nmb_crops,\n",
    "            nmb_kmeans_iters=nmb_kmeans_iters,\n",
    "            device=device,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        training_stats.update(scores)\n",
    "\n",
    "\n",
    "start(\n",
    "    train_dataset=train_dataset,\n",
    "    epochs=1,\n",
    "    nmb_crops=nmb_crops,\n",
    "    crops_for_assign=crops_for_assign,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717224d3-0ae6-4ee0-a341-0ca0b7b7189c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maelstrom-bootcamp-2023",
   "language": "python",
   "name": "maelstrom-bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
